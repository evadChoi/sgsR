[{"path":"/articles/calculating.html","id":"dist","dir":"Articles","previous_headings":"","what":"calculate_distance","title":"calculating","text":"calculate_distance() function takes input raster access data outputs per pixel distance nearest access point. function particular value constraining sampling protocols sample_clhs() function output raster layer can used cost constraint.output raster input calculated distance layer (dist2access) appended.","code":"calculate_distance(raster = sraster, # input                    access = access, # define access road network                    plot = TRUE) # plot #> class       : SpatRaster  #> dimensions  : 277, 373, 2  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> sources     : memory   #>               memory   #> names       :      strata, dist2access  #> min values  : 1.000000000, 0.006621213  #> max values  :        4.00,     1061.66"},{"path":"/articles/calculating.html","id":"calculate_pcomp","dir":"Articles","previous_headings":"","what":"calculate_pcomp","title":"calculating","text":"calculate_pcomp() function take mraster input perform principal component analysis. number components defined nComp parameter specify number components rasterized output.","code":"calculate_pcomp(mraster = mraster, # input                 nComp = 5, # number of components to output                 plot = TRUE, # plot                 details = TRUE) # details about the principal component analysis appended #> $pca #> Standard deviations (1, .., p=7): #> [1] 2.39419952 0.86117918 0.65363319 0.27246138 0.11007946 0.10828637 #> [7] 0.02939539 #>  #> Rotation (n x k) = (7 x 7): #>                PC1         PC2         PC3         PC4         PC5 #> zmean    0.4133334  0.09704163 -0.16917057  0.05440712 -0.22000532 #> pzabove2 0.3217923  0.28576528  0.89947768  0.04709941  0.05904585 #> zsd      0.3314081 -0.70019069  0.06653226 -0.06472512  0.60973701 #> zq20     0.3511220  0.56046214 -0.30856343 -0.47873324  0.46460623 #> zq50     0.4055034  0.12095230 -0.21088469  0.55460643 -0.05871399 #> zq70     0.4116791 -0.07297959 -0.13368861  0.36832636 -0.08204398 #> zq90     0.3982141 -0.29082785  0.01839257 -0.56408691 -0.59185684 #>                   PC6          PC7 #> zmean     0.052917370  0.858462025 #> pzabove2 -0.004146026  0.002415685 #> zsd      -0.098391685  0.099124286 #> zq20      0.032759647 -0.145830192 #> zq50     -0.629977381 -0.261835891 #> zq70      0.755333726 -0.307241076 #> zq90     -0.137941678 -0.262659351 #>  #> $raster #> class       : SpatRaster  #> dimensions  : 277, 373, 5  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> sources     : memory   #>               memory   #>               memory   #>               ... and 2 more source(s) #> names       :        PC1,        PC2,        PC3,        PC4,        PC5  #> min values  : -5.8417985, -6.3694763, -4.0382460, -2.4972669, -0.6925408  #> max values  :   7.806999,   2.565417,   1.633358,   1.598260,   1.530968"},{"path":"/articles/calculating.html","id":"calculate_sampsize","dir":"Articles","previous_headings":"","what":"calculate_sampsize","title":"calculating","text":"calculate_sampsize() function allows users determine appropriate sample size using relative standard error input metric. mraster multiple layers provided, sample sizes determined layers. plot = TRUE rse defined, sequence rse values visualized indicators value matching sample size.","code":"#--- determine sample size based on relative standard error (rse) of 1% ---# calculate_sampsize(mraster = mraster,                    rse = 0.01) #>   nSamp  rse      var #> 1  2030 0.01    zmean #> 2  1341 0.01 pzabove2 #> 3  1859 0.01      zsd #> 4  3647 0.01     zq20 #> 5  2581 0.01     zq50 #> 6  2110 0.01     zq70 #> 7  1394 0.01     zq90 #--- change default threshold sequence values ---#  #--- if increment and rse are not divisible the closes value will be taken ---# p <- calculate_sampsize(mraster = mraster,                    rse = 0.025,                    start = 0.01,                    end = 0.08,                    increment = 0.01,                    plot = TRUE) #> 'rse' not perfectly divisible by 'incremenent.  #> Selecting closest sample size (rse = 0.03) based on values.  p #> $nSamp #> Registered S3 method overwritten by 'cli': #>   method     from          #>   print.boxx spatstat.geom #> # A tibble: 7 x 3 #> # Groups:   var [7] #>   nSamp   rse var      #>   <dbl> <dbl> <chr>    #> 1   230  0.03 zmean    #> 2   151  0.03 pzabove2 #> 3   211  0.03 zsd      #> 4   421  0.03 zq20     #> 5   295  0.03 zq50     #> 6   240  0.03 zq70     #> 7   157  0.03 zq90     #>  #> $plot"},{"path":"/articles/calculating.html","id":"calculate_allocation","dir":"Articles","previous_headings":"","what":"calculate_allocation","title":"calculating","text":"calculate_allocation() function calculates total number samples allocated sampling based total sample value (nSamp) input sraster. function utilized number functions including sample_strat. Three methods allocation currently included: proportional (prop; default), optimal (optim) allocation, equal (equal) allocation. Proportional - Samples allocated based area coverage strata. default method. Optimal - Samples allocated based within strata variation. Equal - number samples (nSamp) allocated strata.","code":""},{"path":"/articles/calculating.html","id":"proportional","dir":"Articles","previous_headings":"calculate_allocation","what":"Proportional allocation","title":"calculating","text":"Notice results total negative. indicates existing samples represent strata samples removed avoid representation. number added/removed details $total.","code":"#--- perform grid sampling ---# calculate_allocation(sraster = sraster,                       nSamp = 200) #>   strata total #> 1      1    47 #> 2      2    57 #> 3      3    41 #> 4      4    54 #--- calculate existing samples to include ---# e.sr <- extract_strata(sraster = sraster,                         existing = existing)  calculate_allocation(sraster = sraster,                       nSamp = 200,                       existing = e.sr) #>   strata total need #> 1      1    -7   47 #> 2      2     8   57 #> 3      3     1   41 #> 4      4    -3   54"},{"path":"/articles/calculating.html","id":"optimal","dir":"Articles","previous_headings":"calculate_allocation","what":"Optimal Allocation","title":"calculating","text":"Optimal allocation utilizes within strata metric variation allocate samples. means addition providing sraster, specific metric (mraster) must provided calculate variation optimally allocate samples.","code":"calculate_allocation(sraster = sraster, # stratified raster                      nSamp = 200, # desired sample number                      existing = e.sr, #existing samples                      allocation = \"optim\", # optimal allocation                      mraster = mraster$zq90, # metric raster                      force = TRUE) # force nSamp number #>   strata total need #> 1      1     5   59 #> 2      2    -1   48 #> 3      3     3   43 #> 4      4    -7   50"},{"path":"/articles/calculating.html","id":"equal","dir":"Articles","previous_headings":"calculate_allocation","what":"Equal allocation","title":"calculating","text":"may instance user wants number samples allocated strata. case using allocation = equal ideal. instance, nSamp relates total number samples per strata rather total number samples overall. yields total 80 samples (20 nSamp 4 strata sraster.)","code":"calculate_allocation(sraster = sraster, # stratified raster                      nSamp = 20, # desired sample number                      allocation = \"equal\") # optimal allocation #> # A tibble: 4 x 2 #>   strata total #>    <dbl> <dbl> #> 1      1    20 #> 2      2    20 #> 3      3    20 #> 4      4    20"},{"path":"/articles/calculating.html","id":"sampeval","dir":"Articles","previous_headings":"","what":"Sample evaluation algorithms","title":"calculating","text":"following algorithms initially developed Dr. Brendan Malone University Sydney. work graciously provided depth description functionality algorithms originally developed improve soil sampling strategies. functions modified implemented can used structurally guided sampling approaches. Many thanks Dr. Malone excellent collaborator proponent open source algorithms. Please consult original reference ideas scripts extremely valuable helpful understanding sampling rationale. Malone BP, Minansy B, Brungard C. 2019. methods improve utility conditioned Latin hypercube sampling. PeerJ 7:e6451 DOI 10.7717/peerj.6451","code":""},{"path":"/articles/calculating.html","id":"coobs","dir":"Articles","previous_headings":"Sample evaluation algorithms","what":"calculate_coobs","title":"calculating","text":"calculate_coobs() function perform COunt OBServations (coobs) algorithm using existing sample data mraster covariates. algorithm aids user understanding existing sample data set distributed among landscape relation mraster covariates. output coobs raster used constrain clhs sampling using sample_clhs() areas reprented. coobs raster determines many observations similar terms covariate space every pixel.fucntion takes advantage parallel processing routines.","code":"calculate_coobs(mraster = mraster, # input                 existing = existing, # existing samples                 cores = 4, # parallel cores to use                 details = TRUE, # provide details from algorithm output                 plot = TRUE, # plot                 filename = tempfile(fileext = \".tif\")) # write output raster to tif"},{"path":"/articles/calculating.html","id":"lhseval","dir":"Articles","previous_headings":"","what":"Latin hypercube sampling evaluation algorithms","title":"calculating","text":"following 2 algorithms provide means maximize effectiveness latin hypercube sampling protocols.","code":""},{"path":"/articles/calculating.html","id":"lhspop","dir":"Articles","previous_headings":"Latin hypercube sampling evaluation algorithms","what":"calculate_lhsPop","title":"calculating","text":"calculate_lhsPop() function calculates population level statistics mraster covariates used including calculating principal components, quantile & covariate distributions, Kullback–Leibler divergence testing. outputs function mandatory use calculate_lhsOpt() function described next section. output details following: $values - Pixel values mraster $pcaLoad - PCA loadings $matQ - Quantile matrix $matCov - Covariate matrix","code":"#--- by default all statistical data are calculated ---# calculate_lhsPop(mraster = mraster) # input #--- statistical analyses can be chosen by setting their parameter to `FALSE` ---# calculate_lhsPop(mraster = mraster, # input                   nQuant = 10, # desired number of quantiles                  PCA = FALSE) # choose not to calculate PCA's"},{"path":"/articles/calculating.html","id":"lhsopt","dir":"Articles","previous_headings":"Latin hypercube sampling evaluation algorithms","what":"calculate_lhsOpt","title":"calculating","text":"calculate_lhsOpt() function performs bootsrapped latin hypercube sampling approach population level analysis mraster data performed determine optimal Latin hypercube sample size. Using statistical data calculated using calculate_lhsPop() varying sample sizes defined minSamp, maxSamp, step rep. Sampling protocols conducted statistical effectiveness sampling outcomes evaluated determine sample size minimized statistical representation maximized.","code":"#--- calculate lhsPop details ---# poplhs <- calculate_lhsPop(mraster = mr)  calculate_lhsOpt(popLHS = poplhs) calculate_lhsOpt(popLHS = poplhs,                   PCA = FALSE,                   iter = 200)"},{"path":"/articles/sampling.html","id":"access","dir":"Articles","previous_headings":"","what":"Access","title":"sampling","text":"feature sample_* functions ability define access corridors. Users can supply road access network (must sf line objects) define buffers around access samples excluded included. Important additional parameters access provided : buff_inner - inner buffer defines distance access samples taken (.e. don’t want samples within 50 m access layer set buff_inner = 50). buff_outer - Maximum distance samples can located access (.e. don’t want samples 200 meters access layer set buff_inner = 200)","code":""},{"path":"/articles/sampling.html","id":"srs","dir":"Articles","previous_headings":"","what":"sample_srs","title":"sampling","text":"provided simple example using sample_srs() function vignette(\"sgsR\"). provide additional examples . Notice input sample_srs() raster. means either sraster mraster supported.","code":"#--- perform simple random sampling ---# sample_srs(raster = sraster, # input sraster            nSamp = 200, # number of desired samples            plot = TRUE) # plot #> Simple feature collection with 200 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431250 ymin: 5337750 xmax: 438550 ymax: 5343190 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (436830 5341150) #> 2  POINT (436830 5341150) #> 3  POINT (436570 5342730) #> 4  POINT (437730 5338210) #> 5  POINT (434490 5339890) #> 6  POINT (431850 5337810) #> 7  POINT (432090 5340270) #> 8  POINT (432970 5337850) #> 9  POINT (431330 5341510) #> 10 POINT (433770 5340590) sample_srs(raster = mraster, # input mraster            nSamp = 200, # number of desired samples            access = access, # define access road network            mindist = 200, # minimum distance samples must be apart from one another            buff_inner = 50, # inner buffer - no samples within this distance from road            buff_outer = 200, # outer buffer - no samples further than this distance from road            plot = TRUE) # plot #> Simple feature collection with 200 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431410 ymin: 5337790 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (438050 5340610) #> 2  POINT (432770 5339130) #> 3  POINT (434970 5340650) #> 4  POINT (438070 5340830) #> 5  POINT (437370 5342730) #> 6  POINT (432510 5338830) #> 7  POINT (432470 5341370) #> 8  POINT (435170 5339310) #> 9  POINT (432810 5340750) #> 10 POINT (432670 5339550) sample_srs(raster = sraster, # input            nSamp = 200, # number of desired samples            access = access, # define access road network            buff_inner = 50, # inner buffer - no samples within this distance from road            buff_outer = 200, # outer buffer - no samples further than this distance from road            plot = TRUE, # plot            filename = tempfile(fileext = \".shp\")) # write output samples to file #> Writing layer `file5c7077074089' to data source  #>   `C:\\Users\\tgood.stu\\AppData\\Local\\Temp\\RtmpwXR6av\\file5c7077074089.shp' using driver `ESRI Shapefile' #> Writing 200 features with 0 fields and geometry type Point. #> Simple feature collection with 200 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431270 ymin: 5337730 xmax: 438550 ymax: 5343210 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (434910 5340590) #> 2  POINT (434910 5340590) #> 3  POINT (433970 5341290) #> 4  POINT (437990 5340070) #> 5  POINT (435390 5338570) #> 6  POINT (433650 5341670) #> 7  POINT (435930 5342370) #> 8  POINT (435090 5338790) #> 9  POINT (431850 5342750) #> 10 POINT (436190 5339650)"},{"path":"/articles/sampling.html","id":"systematic","dir":"Articles","previous_headings":"","what":"sample_systematic","title":"sampling","text":"sample_systematic() function applies systematic sampling across area cellsize parameter defines resolution tessellation. Tesselation shape options defined square parameter, regular grid TRUE (default) hexagonal FALSE. location samples can also adjusted using locations parameter, centers takes center, corners takes corners, random takes random location within tessellation.","code":"#--- perform grid sampling ---# sample_systematic(raster = sraster, # input sraster                   cellsize = 1000, # grid distance                   plot = TRUE) # plot #> Simple feature collection with 40 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431600 ymin: 5338200 xmax: 437600 ymax: 5343200 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (431600 5338200) #> 2  POINT (432600 5338200) #> 3  POINT (433600 5338200) #> 4  POINT (434600 5338200) #> 5  POINT (435600 5338200) #> 6  POINT (436600 5338200) #> 7  POINT (437600 5338200) #> 8  POINT (432600 5339200) #> 9  POINT (433600 5339200) #> 10 POINT (434600 5339200) #--- perform grid sampling ---# sample_systematic(raster = sraster, # input sraster                   cellsize = 500, # grid distance                   square = FALSE, # hexagonal tessellation                   location = \"random\", # random sample within tessellation                   plot = TRUE) # plot #> Simple feature collection with 170 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431108.8 ymin: 5337710 xmax: 438544.8 ymax: 5343206 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                    geometry #> 1  POINT (431108.8 5338509) #> 2    POINT (431227 5339575) #> 3  POINT (431205.1 5341042) #> 4  POINT (431401.4 5337937) #> 5    POINT (431378 5338832) #> 6  POINT (431446.2 5339877) #> 7    POINT (431275 5340777) #> 8  POINT (431369.5 5341441) #> 9  POINT (431348.2 5342633) #> 10 POINT (431692.1 5337855) sample_systematic(raster = sraster, # input sraster             cellsize = 500, # grid distance             access = access, # define access road network             buff_inner = 50, # inner buffer - no samples within this distance from road             buff_outer = 200, # outer buffer - no samples further than this distance from road             square = FALSE, # hexagonal tessellation             location = \"corners\", # take corners instead of centers             plot = TRUE) #> Simple feature collection with 470 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337844 xmax: 438350 ymax: 5343185 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (431100 5340875) #> 2  POINT (431100 5340587) #> 3  POINT (431100 5340587) #> 4  POINT (431350 5340442) #> 5  POINT (431100 5340875) #> 6  POINT (431100 5340875) #> 7  POINT (431350 5342752) #> 8  POINT (431350 5340442) #> 9  POINT (431100 5340587) #> 10 POINT (431100 5340875)"},{"path":"/articles/sampling.html","id":"sstrat","dir":"Articles","previous_headings":"","what":"sample_strat","title":"sampling","text":"sample_strat() function contains hierarchical sampling algorithm originally developed Martin Queinnec. Queinnec, M., White, J. C., & Coops, N. C. (2021). Comparing airborne spaceborne photon-counting LiDAR canopy structural estimates across different boreal forest types. Remote Sensing Environment, 262(August 2020), 112510. algorithm uses moving window (wrow wcol parameters) filter input sraster locations stratum pixels spatially grouped rather dispersed individually across landscape. sampling performed 2 stages: Rule 1 - Sample within spatially grouped stratum pixels. Moving window defined wrow wcol. Rule 2 - samples exist satisfy desired sampling count, individual stratum pixels sampled. rule applied select particular sample defined rule attribute output samples. give examples :  cases, user may wish include existing sample data set within algorithm. order adjust total number samples needed per stratum reflect already present existing, can use utility function extract_strata(). function takes input sraster existing sample data set extracts stratum sample. samples can input sample_strat() function adjusts total required sample per class based representation existing. Notice e.sr now attribute named strata. parameter , sample_strat() give error.  mindist parameter defined example specifies minimum euclidian distance samples must apat one another. Notice sample outputs type rule attributes outline whether samples existing new whether rule1 rule2 used select individual samples.  include parameter determines whether existing samples included total count samples defined nSamp. defaults include = FALSE.","code":"#--- perform stratified sampling random sampling ---# sample_strat(sraster = sraster, # input sraster              nSamp = 200, # desired sample number              plot = TRUE) # plot #> Simple feature collection with 199 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431150 ymin: 5337730 xmax: 438530 ymax: 5343210 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>    strata type  rule               geometry #> x       1  new rule1 POINT (434510 5341590) #> x1      1  new rule1 POINT (437550 5343210) #> x2      1  new rule1 POINT (437610 5339170) #> x3      1  new rule1 POINT (438010 5338130) #> x4      1  new rule1 POINT (434210 5341710) #> x5      1  new rule1 POINT (434950 5342870) #> x6      1  new rule1 POINT (437650 5342590) #> x7      1  new rule1 POINT (436750 5337730) #> x8      1  new rule1 POINT (437850 5338990) #> x9      1  new rule1 POINT (435930 5342330) #--- extract strata values to existing samples ---#               e.sr <- extract_strata(sraster = sraster, # input sraster                        existing = existing) # existing samples to add strata value to  e.sr #> Simple feature collection with 200 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337730 xmax: 438550 ymax: 5343230 #> Projected CRS: UTM Zone 17, Northern Hemisphere #> First 10 features: #>    strata               geometry #> 1       1 POINT (434610 5338890) #> 2       3 POINT (437190 5342830) #> 3       4 POINT (434950 5338430) #> 4       4 POINT (436090 5339590) #> 5       1 POINT (438190 5337850) #> 6       1 POINT (434770 5339830) #> 7       2 POINT (434090 5341690) #> 8       3 POINT (432050 5341670) #> 9       1 POINT (434110 5343130) #> 10      4 POINT (432490 5342030) sample_strat(sraster = sraster, # input sraster              nSamp = 200, # desired sample number              access = access, # define access road network              existing = e.sr, # existing samples with strata values              mindist = 200, # minimum distance samples must be apart from one another              buff_inner = 50, # inner buffer - no samples within this distance from road              buff_outer = 200, # outer buffer - no samples further than this distance from road              plot = TRUE) # plot #> Simple feature collection with 399 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337730 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>    strata     type     rule               geometry #> 1       1 existing existing POINT (434610 5338890) #> 5       1 existing existing POINT (438190 5337850) #> 6       1 existing existing POINT (434770 5339830) #> 9       1 existing existing POINT (434110 5343130) #> 15      1 existing existing POINT (434950 5342270) #> 23      1 existing existing POINT (434110 5339470) #> 25      1 existing existing POINT (435570 5342750) #> 32      1 existing existing POINT (434870 5342530) #> 34      1 existing existing POINT (438210 5338310) #> 40      1 existing existing POINT (434290 5340830) sample_strat(sraster = sraster, # input              nSamp = 200, # desired sample number              access = access, # define access road network              existing = e.sr, # existing samples with strata values              include = TRUE, # include existing plots in nSamp total              buff_inner = 50, # inner buffer - no samples within this distance from road              buff_outer = 200, # outer buffer - no samples further than this distance from road              filename = tempfile(fileext = \".shp\"), # write output samples to file              plot = TRUE) # plot #> Writing layer `file5c7024661b59' to data source  #>   `C:\\Users\\tgood.stu\\AppData\\Local\\Temp\\RtmpwXR6av\\file5c7024661b59.shp' using driver `ESRI Shapefile' #> Writing 199 features with 3 fields and geometry type Point. #> Simple feature collection with 199 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337730 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>     strata     type     rule               geometry #> 40       1 existing existing POINT (434290 5340830) #> 41       1 existing existing POINT (435130 5342390) #> 83       1 existing existing POINT (434330 5341610) #> 58       1 existing existing POINT (438510 5338990) #> 119      1 existing existing POINT (434530 5341290) #> 126      1 existing existing POINT (433930 5342650) #> 194      1 existing existing POINT (437850 5343030) #> 59       1 existing existing POINT (437370 5338530) #> 34       1 existing existing POINT (438210 5338310) #> 96       1 existing existing POINT (433890 5342950)"},{"path":"/articles/sampling.html","id":"clhs","dir":"Articles","previous_headings":"","what":"sample_clhs","title":"sampling","text":"sample_clhs() function implements conditioned latin hypercube (clhs) sampling functionality. number functions sgsR package help provide guidance clhs sampling including calculate_lhsPop() calculate_lhsOpt(). sure check functions better understanding optimize sample numbers. Syntax function similar others shown , though parameters like iter, define number iterations within Metropolis-Hastings process important consider. examples use low iter value takes less time run. Default values iter within clhs package 10,000.    cost parameter defines mraster covariate used constrain clhs sampling. number variables. example distance pixel road access (see example ), terrain slope, output calculate_coobs(), many others.","code":"sample_clhs(mraster = mraster, # input             nSamp = 200, # desired sample number             plot = TRUE, # plot              iter = 100) # number of iterations sample_clhs(mraster = mraster, # input             nSamp = 300, # desired sample number             existing = existing, # existing samples             iter = 100, # number of iterations             details = TRUE, # output details             plot = TRUE) # clhs details sample_clhs(mraster = mraster, # input             nSamp = 300, # desired sample number             iter = 100, # number of iterations             existing = existing, # existing samples             access = access, # define access road network             buff_inner = 100, # inner buffer - no samples within this distance from road             buff_outer = 300, # outer buffer - no samples further than this distance from road             plot = TRUE) # plot #--- cost constrained examples ---# #--- calculate distance to access layer for each pixel in mr ---# mr.c <- calculate_distance(raster = mraster, # input                            access = access,                            plot = TRUE) # define access road network sample_clhs(mraster = mr.c, # input             nSamp = 250, # desired sample number             iter = 100, # number of iterations             cost = \"dist2access\", # cost parameter - name defined in calculate_distance()             plot = TRUE) # plot sample_clhs(mraster = mr.c, # input             nSamp = 250, # desired sample number             existing = existing, # existing samples             iter = 100, # number of iterations             cost = \"dist2access\", # cost parameter - name defined in calculate_distance()             plot = TRUE) # plot"},{"path":"/articles/sampling.html","id":"balanced","dir":"Articles","previous_headings":"","what":"sample_balanced","title":"sampling","text":"sample_balanced() algorithm performs balanced sampling methodology stratifyR / SamplingBigData packages.","code":"sample_balanced(mraster = mraster, # input                 nSamp = 200, # desired sample number                 plot = TRUE) # plot #> Simple feature collection with 200 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431230 ymin: 5337710 xmax: 438530 ymax: 5343190 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (432810 5343190) #> 2  POINT (434050 5343190) #> 3  POINT (433370 5343010) #> 4  POINT (437250 5343010) #> 5  POINT (437890 5343010) #> 6  POINT (433190 5342990) #> 7  POINT (435370 5342950) #> 8  POINT (432050 5342930) #> 9  POINT (433830 5342870) #> 10 POINT (433030 5342850) sample_balanced(mraster = mraster, # input                 nSamp = 100, # desired sample number                 algorithm = \"lcube\", # algorithm type                 access = access, # define access road network                 buff_inner = 50, # inner buffer - no samples within this distance from road                 buff_outer = 200) # outer buffer - no samples further than this distance from road #> Simple feature collection with 100 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431410 ymin: 5337770 xmax: 438470 ymax: 5343190 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (434090 5342890) #> 2  POINT (438170 5342030) #> 3  POINT (435090 5342410) #> 4  POINT (435810 5340190) #> 5  POINT (436530 5338190) #> 6  POINT (437170 5343170) #> 7  POINT (436210 5339350) #> 8  POINT (438170 5342010) #> 9  POINT (432670 5338910) #> 10 POINT (438390 5339110)"},{"path":"/articles/sampling.html","id":"ahels","dir":"Articles","previous_headings":"","what":"sample_ahels","title":"sampling","text":"sample_ahels() function performs adapted Hypercube Evaluation Legacy Sample (ahels) algorithm using existing sample data mraster. New samples allocated based quantile ratios existing sample mraster covariate dataset. algorithm: Determines quantile distributions existing samples mraster covariates. Determines quantiles disparity samples covariates. Prioritizes sampling within quantile improve representation. use function, user first specify number quantiles (nQuant) followed either nSamp (total number desired samples added) threshold (proportional representation sample covariate quantiles - default 0.9) parameters. recommended use threshold values 0.9 higher values can currently cause algorithm add samples repeatedly.  Notice threshold, nSamp, nQuant defined. Thats defaults threshold = 0.9 nQuant = 10. first matrix output shows quantile ratios sample covariates. value 1.0 means samples covariates equally represented. Values 1.0 represented sample, less 1 represented sample.  Note total number samples 500. total existing samples (200) number defined nSamp = 300.","code":"sample_ahels(mraster = mraster[[1:3]], # input mraster - first 3 layers only              existing = existing, # existing samples              plot = TRUE) # plot #> Simple feature collection with 246 features and 4 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337730 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>        type zmean pzabove2  zsd               geometry #> 1  existing  5.02      8.3 6.18 POINT (434610 5338890) #> 2  existing  5.85     75.1 3.02 POINT (437190 5342830) #> 3  existing 14.78     96.7 6.79 POINT (434950 5338430) #> 4  existing 16.62     76.6 7.58 POINT (436090 5339590) #> 5  existing  4.59     34.3 2.53 POINT (438190 5337850) #> 6  existing  4.07     29.0 2.32 POINT (434770 5339830) #> 7  existing 11.05     97.6 4.04 POINT (434090 5341690) #> 8  existing  6.10     70.5 2.56 POINT (432050 5341670) #> 9  existing  4.50     90.6 2.44 POINT (434110 5343130) #> 10 existing 13.75     77.1 4.37 POINT (432490 5342030) sample_ahels(mraster = mraster[[1:3]], # input mraster - first 3 layers only              existing = existing, # existing samples              nQuant = 20, # define 20 quantiles              nSamp = 300, # total samples desired              filename = tempfile(fileext = \".shp\")) # write samples to disc #> Simple feature collection with 500 features and 4 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337730 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>        type zmean pzabove2  zsd               geometry #> 1  existing  5.02      8.3 6.18 POINT (434610 5338890) #> 2  existing  5.85     75.1 3.02 POINT (437190 5342830) #> 3  existing 14.78     96.7 6.79 POINT (434950 5338430) #> 4  existing 16.62     76.6 7.58 POINT (436090 5339590) #> 5  existing  4.59     34.3 2.53 POINT (438190 5337850) #> 6  existing  4.07     29.0 2.32 POINT (434770 5339830) #> 7  existing 11.05     97.6 4.04 POINT (434090 5341690) #> 8  existing  6.10     70.5 2.56 POINT (432050 5341670) #> 9  existing  4.50     90.6 2.44 POINT (434110 5343130) #> 10 existing 13.75     77.1 4.37 POINT (432490 5342030)"},{"path":"/articles/sgsR.html","id":"str","dir":"Articles","previous_headings":"","what":"Algorithm structure","title":"sgsR","text":"sgsR scripted primarily using terra package raster processing sf package vector manipulation. 3 primary function verbs package currently uses: strat_* - stratify verb implies functions applying stratification algorithms input metrics raster mraster output stratified raster sraster. sample_* - sample verb implies functions extracting samples srasters produced strat_* functions. algorithms (e.g. sample_srs(), sample_balanced(), sample_systematic()) able take mrasters inputs dependent stratified inputs sampling. calculate_* - calculate verb implies functions performing calculations used consequent processing. use predefined sample analysis algorithms calculate_ahels(), calculate_coobs() also included.","code":""},{"path":"/articles/sgsR.html","id":"example-data","dir":"Articles","previous_headings":"","what":"Example data","title":"sgsR","text":"Worked examples functions provided using data internal package. load internal mraster road access data use following code. Follow along machine see outputs get better sense package functions.","code":""},{"path":"/articles/sgsR.html","id":"mrast","dir":"Articles","previous_headings":"Example data","what":"Metrics rasters - mraster","title":"sgsR","text":"","code":"library(sgsR) library(terra) library(sf)  #--- Load mraster and access files ---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\")  #--- load the mraster using the terra package ---# mraster <- terra::rast(r)"},{"path":"/articles/sgsR.html","id":"vect","dir":"Articles","previous_headings":"Example data","what":"Road access data","title":"sgsR","text":"plot see first band (zmax) mraster access vector overlaid.","code":"a <- system.file(\"extdata\", \"roads.shp\", package = \"sgsR\")  #--- load the access vector using the sf package ---# access <- sf::st_read(a) #> Reading layer `roads' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\roads.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 167 features and 2 fields #> Geometry type: MULTILINESTRING #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337700 xmax: 438560 ymax: 5343240 #> Projected CRS: UTM_Zone_17_Northern_Hemisphere terra::plot(mraster[[1]]) terra::plot(access, add = TRUE, col = \"black\")"},{"path":"/articles/sgsR.html","id":"srast","dir":"Articles","previous_headings":"","what":"Stratified rasters - sraster","title":"sgsR","text":"purposes tutorial also going show produce basic sraster existing sample data used examples . make sraster use strat_kmeans() function input mraster stratified using kmeans algorithm.  sraster produced apply sample_srs() algorithm randomly samples points within sraster produce existing sample dataset.  now mraster, access, sraster existing data sets generated. Expect see data used examples document.","code":"#--- apply kmeans algorithm to metrics raster ---# sraster <- strat_kmeans(mraster = mraster, # use mraster as input for sampling                         nStrata = 4, # algorithm will produce 4 strata                         plot = TRUE) # algorithm will plot output #--- set seed ---# set.seed(2021)  #--- apply kmeans algorithm to metrics raster ---# existing <- sample_srs(raster = mraster, # use mraster as input for sampling                        nSamp = 200, # request 200 samples be taken                        mindist = 100, # define that samples must be 100 m apart                        plot = TRUE) # algorithm will plot output"},{"path":"/articles/sgsR.html","id":"pipe","dir":"Articles","previous_headings":"","what":"%>%","title":"sgsR","text":"sgsR package leverages %>% operator magrittr package. allows us “pipe” operations together save amount code needed achieve outcome. simple example .","code":"#--- non piped ---# sraster <- strat_kmeans(mraster = mraster, # use mraster as input for sampling                         nStrata = 4, # algorithm will produce 4 strata                         plot = TRUE) # algorithm will plot output  existing <- sample_srs(raster = sraster, # use mraster as input for sampling                        nSamp = 200, # request 200 samples be taken                        mindist = 100, # define that samples must be 100 m apart                        plot = TRUE) # algorithm will plot output  extract_metrics(mraster = mraster,                 existing = existing)   #--- piped ---# strat_kmeans(mraster = mraster, nStrata = 4) %>%   sample_srs(., nSamp = 200, mindist = 100) %>%   extract_metrics(mraster = mraster, existing = .)"},{"path":"/articles/stratification.html","id":"kmeans","dir":"Articles","previous_headings":"","what":"strat_kmeans","title":"stratification","text":"provide preliminary example strat_kmeans() algorithm prepare sraster input data . Notice nothing plotted… ’s plot = FALSE default functions sgsR. See examples plot = TRUE.","code":"#--- perform stratification using k-means ---# strat_kmeans(mraster = mraster, # input              nStrata = 5) # algorithm will produce 4 strata #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      5 strat_kmeans(mraster = mraster, # input              nStrata = 10, # algorithm will produce 10 strata              iter = 1000, # set minimum number of iterations to determine kmeans centers              algorithm = \"MacQueen\", # use MacQueen algorithm              plot = TRUE) # plot output #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :     10 strat_kmeans(mraster = mraster, # input              nStrata = 5, # algorithm will produce 4 strata              center = FALSE, # do not center data              scale = FALSE, # do not scale data              plot = TRUE, # plot output              filename = tempfile(fileext = \".tif\"), # write output sraster to file              overwrite = TRUE) # overwrite file on disc if it exists #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      5"},{"path":"/articles/stratification.html","id":"strat_quantiles","dir":"Articles","previous_headings":"","what":"strat_quantiles","title":"stratification","text":"strat_quantiles() algorithm divides data equally sized strata (nStrata). Similar strat_breaks(), algorithm allows stratification single mraster, user can supply secondary mraster (mraster2) specify associated number desired strata (nStrata2). dual stratification output always result product \\(nStrata * nStrata2\\).","code":"#--- perform quantiles stratification ---# strat_quantiles(mraster = mraster$zq90,                 nStrata = 6,                 plot = TRUE) #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      6  #--- dual stratification - will produce 12 output strata ---# strat_quantiles(mraster = mraster$zq90,                  mraster2 = mraster$zsd,                 nStrata = 3,                  nStrata2 = 4) #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :     12"},{"path":"/articles/stratification.html","id":"strat_breaks","dir":"Articles","previous_headings":"","what":"strat_breaks","title":"stratification","text":"strat_breaks() function stratifies data based user-defined breaks covariates. single metric can defined additional metric2 can supplied. breaks breaks2 correspond user-defined breaks metric metric2 respectively. breaks created can input function using breaks breaks2 parameters.","code":"#--- perform stratification using user-defined breaks ---#  #--- define breaks for metric ---# breaks <- c(seq(0,100,20))  breaks #> [1]   0  20  40  60  80 100  #--- perform stratification using user-defined breaks ---#  values <- terra::values(mraster$zq90)  #--- define breaks for metric ---# breaks2 <- c(5,10,15,20,25)  breaks2 #> [1]  5 10 15 20 25 #--- stratify on 1 metric only ---#  strat_breaks(mraster = mraster$pzabove2,              breaks = breaks,              plot = TRUE) #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      6 #--- stratify on 1 metric only ---#  strat_breaks(mraster = mraster$zq90,              breaks = breaks2,              plot = TRUE) #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      6"},{"path":"/articles/stratification.html","id":"strat_poly","dir":"Articles","previous_headings":"","what":"strat_poly","title":"stratification","text":"strat_poly() algorithm stratifies based spatial polygon attributes features. user may wish stratify based categorical empirical variables given ALS data (e.g. species forest inventory polygons). method allows user define attribute interest well features within attributes grouped stratification. user defines input poly associated attribute. raster layer must provided guide spatial extent resolution output stratification polygon. Based vector list features, stratification applied, polygon rasterized appropriate strata. attribute column must defined, features within must specified define number composition output strata. case attribute = \"NUTRIENTS\" features within NUTRIENTS (poor, rich, medium) define 3 desired output classes.  features can also made amalgamate classes. example rich medium features combined low left alone. 2 vectors added list, outputs 2 classes (low & rich/medium).  notice details parameter present . returns output outRaster, $lookUp table associated strata, polygon ($poly) created drive stratification based attribute features provided users.","code":"#--- load in polygon coverage ---# poly <- system.file(\"extdata\", \"inventory_polygons.shp\", package = \"sgsR\")  fri <- sf::st_read(poly) #> Reading layer `inventory_polygons' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\inventory_polygons.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 632 features and 3 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337700 xmax: 438560 ymax: 5343240 #> Projected CRS: UTM_Zone_17_Northern_Hemisphere #--- stratify polygon coverage ---# #--- specify polygon attribute to stratify ---#  attribute <- \"NUTRIENTS\"  #--- specify features within attribute & how they should be grouped ---# #--- as a single vector ---#  features <- c(\"poor\", \"rich\", \"medium\")  srasterpoly <- strat_poly(poly = fri, # input polygon                           attribute = attribute, # attribute to stratify by                           features = features, # features within attribute                           raster = sraster, # raster to define extent and resolution for output                           plot = TRUE) # plot output #--- or as multiple lists ---# g1 <- \"poor\" g2 <- c(\"rich\", \"medium\")  features <- list(g1, g2)  strat_poly(poly = fri,            attribute = attribute,            features = features,            raster = sraster,            plot = TRUE,            details = TRUE) #> $outRaster #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      2  #>  #> $lookUp #>   strata features #> 1      1     poor #> 2      2     rich #> 3      2   medium #>  #> $poly #>  class       : SpatVector  #>  geometry    : polygons  #>  dimensions  : 524, 2  (geometries, attributes) #>  extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #>  coord. ref. : UTM_Zone_17_Northern_Hemisphere  #>  names       : NUTRIENTS strata #>  type        :     <chr>  <num> #>  values      :      poor      1 #>                     poor      1 #>                     poor      1"},{"path":"/articles/stratification.html","id":"strat_map","dir":"Articles","previous_headings":"","what":"strat_map","title":"stratification","text":"may instance multiple levels stratification desired. instance user may want combine output strat_poly() 3 classes, 4 class kmeans stratification kmeans. total number classes always multiplicative number strata. .e. sraster 3 strata sraster2 4 strata output strat_map() 12 strata total.  convention numeric value output strata concatenation (merging) sraster strata sraster2 strata. See $lookUp clear depiction .","code":"#--- map srasters ---# strat_map(sraster = srasterpoly, # strat_poly 3 class stratification           sraster2 = sraster, # strat_kmeans 4 class stratification           plot = TRUE) #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :     11  #> max value   :     34 strat_map(sraster = srasterpoly, # strat_poly 3 class stratification           sraster2 = sraster, # strat_poly 3 class stratification           stack = TRUE, # stack input and oputput strata into multi layer ouput raster           details = TRUE, # provide additional details           plot = TRUE) # plot output #> Stacking sraster, sraster2, and their combination (stratamapped). #> $outRaster #> class       : SpatRaster  #> dimensions  : 277, 373, 3  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> sources     : memory   #>               memory   #>               memory   #> names       : strata, strata2, stratamapped  #> min values  :      1,       1,           11  #> max values  :      3,       4,           34  #>  #> $lookUp #>    strata strata2 stratamapped #> 1       3       2           32 #> 2       3       1           31 #> 3       1       4           14 #> 4       1       3           13 #> 5       3       4           34 #> 6       3       3           33 #> 7       1       2           12 #> 8       1       1           11 #> 9       2       1           21 #> 10      2       2           22 #> 11      2       4           24 #> 12      2       3           23"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Tristan RH Goodbody. Author, maintainer. Nicholas C Coops. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Tristan RH Goodbody Nicholas C Coops (2022). Structurally Guided Sampling Approaches using ALS Data. R package version 1.0.0. https://github.com/tgoodbody/sgsR","code":"@Manual{,   title = {Structurally Guided Sampling Approaches using ALS Data},   author = {Tristan RH Goodbody and Nicholas C Coops},   year = {2022},   note = {R package version 1.0.0},   url = {https://github.com/tgoodbody/sgsR}, }"},{"path":"/index.html","id":"sgsr---structurally-guided-sampling-","dir":"","previous_headings":"","what":"sgsR","title":"sgsR","text":"sgsR designed implement structurally guided sampling approaches enhanced forest inventories. package designed function using rasterized airborne laser scanning (ALS; Lidar) metrics allow stratification forested areas based structure.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"sgsR","text":"can install released version sgsR Github :","code":"install.packages(\"devtools\") devtools::install_github(\"https://github.com/tgoodbody/sgsR\") library(sgsR)"},{"path":"/index.html","id":"implementation","dir":"","previous_headings":"","what":"Implementation","title":"sgsR","text":"Describe package fundamentals - vignette(\"sgsR\") Overview sampling algorithms - vignette(\"sampling\") Overview stratification algorithms - vignette(\"stratification\") Overview calculate algorithms - vignette(\"calculating\")","code":""},{"path":"/index.html","id":"collaborators","dir":"","previous_headings":"","what":"Collaborators","title":"sgsR","text":"thankful continued collaboration academic, private industry, government institutions help improve sgsR. Special thanks :","code":""},{"path":"/index.html","id":"funding","dir":"","previous_headings":"","what":"Funding","title":"sgsR","text":"Development sgsR made possible thanks financial support Canadian Wood Fibre Centre’s Forest Innovation Program.","code":""},{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"/LICENSE.html","id":"0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"/LICENSE.html","id":"1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"/LICENSE.html","id":"2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"/LICENSE.html","id":"3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"/LICENSE.html","id":"4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"/LICENSE.html","id":"5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"/LICENSE.html","id":"6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"/LICENSE.html","id":"7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"/LICENSE.html","id":"8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"/LICENSE.html","id":"9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"/LICENSE.html","id":"10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"/LICENSE.html","id":"11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"/LICENSE.html","id":"12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"/LICENSE.html","id":"13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"/LICENSE.html","id":"14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"/LICENSE.html","id":"15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"/LICENSE.html","id":"16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"/LICENSE.html","id":"17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"/reference/calculate_ahels.html","id":null,"dir":"Reference","previous_headings":"","what":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — calculate_ahels","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — calculate_ahels","text":"Perform adapted Hypercube Evaluation Legacy Sample (ahels) algorithm using existing site data raster metrics. New samples allocated based quantile ratios existing sample covariate dataset.","code":""},{"path":"/reference/calculate_ahels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — calculate_ahels","text":"","code":"calculate_ahels(   mraster,   existing,   nQuant = 10,   nSamp = NULL,   threshold = 0.9,   plot = FALSE,   details = FALSE,   filename = NULL,   overwrite = FALSE )"},{"path":"/reference/calculate_ahels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — calculate_ahels","text":"mraster spatRaster. ALS metrics raster. existing sf. Samples resulting sample_* functions. nQuant Numeric. Number quantiles divide covariates samples . Quantiles cover least 1 percent area interest excluded returned NA. nSamp Numeric. Maximum number new samples allocate. provided, algorithm default allocating number samples provided. threshold Numeric. sample quantile ratio threshold establishing whether additional samples added. default = 0.9. Values close 1 can cause algorithm continually loop used sparingly. plot Logial. Plots existing (circles) new (crosses) samples first band mraster. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc.","code":""},{"path":"/reference/calculate_ahels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — calculate_ahels","text":"Returns sf point object existing samples supplemental samples added ahels algorithm.","code":""},{"path":"/reference/calculate_ahels.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — calculate_ahels","text":"Special thanks Dr. Brendan Malone original implementation algorithm.","code":""},{"path":"/reference/calculate_ahels.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — calculate_ahels","text":"Malone BP, Minansy B, Brungard C. 2019. methods improve utility conditioned Latin hypercube sampling. PeerJ 7:e6451 DOI 10.7717/peerj.6451","code":""},{"path":[]},{"path":"/reference/calculate_ahels.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — calculate_ahels","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/calculate_ahels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — calculate_ahels","text":"","code":"#--- Load raster and existing plots---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  e <- system.file(\"extdata\", \"existing.shp\", package = \"sgsR\") e <- sf::st_read(e) #> Reading layer `existing' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\existing.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 100 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           unknown  calculate_ahels(   mraster = mr[[1:3]],   existing = e,   plot = TRUE ) #> Creating covariance matrix. #>    |                                                                       |                                                              |   0%   |                                                                       |                                                              |   1%   |                                                                       |=                                                             |   1%   |                                                                       |=                                                             |   2%   |                                                                       |==                                                            |   2%   |                                                                       |==                                                            |   3%   |                                                                       |==                                                            |   4%   |                                                                       |===                                                           |   4%   |                                                                       |===                                                           |   5%   |                                                                       |===                                                           |   6%   |                                                                       |====                                                          |   6%   |                                                                       |====                                                          |   7%   |                                                                       |=====                                                         |   7%   |                                                                       |=====                                                         |   8%   |                                                                       |=====                                                         |   9%   |                                                                       |======                                                        |   9%   |                                                                       |======                                                        |  10%   |                                                                       |=======                                                       |  10%   |                                                                       |=======                                                       |  11%   |                                                                       |=======                                                       |  12%   |                                                                       |========                                                      |  12%   |                                                                       |========                                                      |  13%   |                                                                       |========                                                      |  14%   |                                                                       |=========                                                     |  14%   |                                                                       |=========                                                     |  15%   |                                                                       |==========                                                    |  15%   |                                                                       |==========                                                    |  16%   |                                                                       |==========                                                    |  17%   |                                                                       |===========                                                   |  17%   |                                                                       |===========                                                   |  18%   |                                                                       |===========                                                   |  19%   |                                                                       |============                                                  |  19%   |                                                                       |============                                                  |  20%   |                                                                       |=============                                                 |  20%   |                                                                       |=============                                                 |  21%   |                                                                       |=============                                                 |  22%   |                                                                       |==============                                                |  22%   |                                                                       |==============                                                |  23%   |                                                                       |===============                                               |  23%   |                                                                       |===============                                               |  24%   |                                                                       |===============                                               |  25%   |                                                                       |================                                              |  25%   |                                                                       |================                                              |  26%   |                                                                       |================                                              |  27%   |                                                                       |=================                                             |  27%   |                                                                       |=================                                             |  28%   |                                                                       |==================                                            |  28%   |                                                                       |==================                                            |  29%   |                                                                       |==================                                            |  30%   |                                                                       |===================                                           |  30%   |                                                                       |===================                                           |  31%   |                                                                       |====================                                          |  31%   |                                                                       |====================                                          |  32%   |                                                                       |====================                                          |  33%   |                                                                       |=====================                                         |  33%   |                                                                       |=====================                                         |  34%   |                                                                       |=====================                                         |  35%   |                                                                       |======================                                        |  35%   |                                                                       |======================                                        |  36%   |                                                                       |=======================                                       |  36%   |                                                                       |=======================                                       |  37%   |                                                                       |=======================                                       |  38%   |                                                                       |========================                                      |  38%   |                                                                       |========================                                      |  39%   |                                                                       |========================                                      |  40%   |                                                                       |=========================                                     |  40%   |                                                                       |=========================                                     |  41%   |                                                                       |==========================                                    |  41%   |                                                                       |==========================                                    |  42%   |                                                                       |==========================                                    |  43%   |                                                                       |===========================                                   |  43%   |                                                                       |===========================                                   |  44%   |                                                                       |============================                                  |  44%   |                                                                       |============================                                  |  45%   |                                                                       |============================                                  |  46%   |                                                                       |=============================                                 |  46%   |                                                                       |=============================                                 |  47%   |                                                                       |=============================                                 |  48%   |                                                                       |==============================                                |  48%   |                                                                       |==============================                                |  49%   |                                                                       |===============================                               |  49%   |                                                                       |===============================                               |  50%   |                                                                       |===============================                               |  51%   |                                                                       |================================                              |  51%   |                                                                       |================================                              |  52%   |                                                                       |=================================                             |  52%   |                                                                       |=================================                             |  53%   |                                                                       |=================================                             |  54%   |                                                                       |==================================                            |  54%   |                                                                       |==================================                            |  55%   |                                                                       |==================================                            |  56%   |                                                                       |===================================                           |  56%   |                                                                       |===================================                           |  57%   |                                                                       |====================================                          |  57%   |                                                                       |====================================                          |  58%   |                                                                       |====================================                          |  59%   |                                                                       |=====================================                         |  59%   |                                                                       |=====================================                         |  60%   |                                                                       |======================================                        |  60%   |                                                                       |======================================                        |  61%   |                                                                       |======================================                        |  62%   |                                                                       |=======================================                       |  62%   |                                                                       |=======================================                       |  63%   |                                                                       |=======================================                       |  64%   |                                                                       |========================================                      |  64%   |                                                                       |========================================                      |  65%   |                                                                       |=========================================                     |  65%   |                                                                       |=========================================                     |  66%   |                                                                       |=========================================                     |  67%   |                                                                       |==========================================                    |  67%   |                                                                       |==========================================                    |  68%   |                                                                       |==========================================                    |  69%   |                                                                       |===========================================                   |  69%   |                                                                       |===========================================                   |  70%   |                                                                       |============================================                  |  70%   |                                                                       |============================================                  |  71%   |                                                                       |============================================                  |  72%   |                                                                       |=============================================                 |  72%   |                                                                       |=============================================                 |  73%   |                                                                       |==============================================                |  73%   |                                                                       |==============================================                |  74%   |                                                                       |==============================================                |  75%   |                                                                       |===============================================               |  75%   |                                                                       |===============================================               |  76%   |                                                                       |===============================================               |  77%   |                                                                       |================================================              |  77%   |                                                                       |================================================              |  78%   |                                                                       |=================================================             |  78%   |                                                                       |=================================================             |  79%   |                                                                       |=================================================             |  80%   |                                                                       |==================================================            |  80%   |                                                                       |==================================================            |  81%   |                                                                       |===================================================           |  81%   |                                                                       |===================================================           |  82%   |                                                                       |===================================================           |  83%   |                                                                       |====================================================          |  83%   |                                                                       |====================================================          |  84%   |                                                                       |====================================================          |  85%   |                                                                       |=====================================================         |  85%   |                                                                       |=====================================================         |  86%   |                                                                       |======================================================        |  86%   |                                                                       |======================================================        |  87%   |                                                                       |======================================================        |  88%   |                                                                       |=======================================================       |  88%   |                                                                       |=======================================================       |  89%   |                                                                       |=======================================================       |  90%   |                                                                       |========================================================      |  90%   |                                                                       |========================================================      |  91%   |                                                                       |=========================================================     |  91%   |                                                                       |=========================================================     |  92%   |                                                                       |=========================================================     |  93%   |                                                                       |==========================================================    |  93%   |                                                                       |==========================================================    |  94%   |                                                                       |===========================================================   |  94%   |                                                                       |===========================================================   |  95%   |                                                                       |===========================================================   |  96%   |                                                                       |============================================================  |  96%   |                                                                       |============================================================  |  97%   |                                                                       |============================================================  |  98%   |                                                                       |============================================================= |  98%   |                                                                       |============================================================= |  99%   |                                                                       |==============================================================|  99%   |                                                                       |==============================================================| 100% #> threshold of 0.9 has been provided. Samples will be added until quantile ratio is reached #> Underrepresented Quantile 1 - A total of 11 samples have been allocated. #> Underrepresented Quantile 2 - A total of 2 samples have been allocated. #> Underrepresented Quantile 3 - A total of 2 samples have been allocated. #> Underrepresented Quantile 4 - A total of 4 samples have been allocated. #> Underrepresented Quantile 5 - A total of 3 samples have been allocated. #> Underrepresented Quantile 6 - A total of 4 samples have been allocated. #> Underrepresented Quantile 7 - A total of 5 samples have been allocated. #> Underrepresented Quantile 8 - A total of 5 samples have been allocated. #> Underrepresented Quantile 9 - A total of 2 samples have been allocated. #> Underrepresented Quantile 10 - A total of 3 samples have been allocated. #> Underrepresented Quantile 11 - A total of 3 samples have been allocated. #> Underrepresented Quantile 12 - A total of 3 samples have been allocated. #> Underrepresented Quantile 13 - A total of 1 samples have been allocated. #> Underrepresented Quantile 14 - A total of 4 samples have been allocated. #> A total of 52 new samples added  #> Simple feature collection with 152 features and 4 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>        type     zmean pzabove2  zsd               geometry #> 1  existing 11.490000     79.7 4.96 POINT (434970 5343030) #> 2  existing 10.679999     91.9 3.90 POINT (435590 5340510) #> 3  existing  5.640000     24.8 4.23 POINT (434290 5338670) #> 4  existing  7.490000     38.5 3.61 POINT (435170 5340410) #> 5  existing  9.170000     69.4 4.20 POINT (437550 5340650) #> 6  existing 11.059999     79.8 5.30 POINT (435850 5340130) #> 7  existing  9.240000     74.8 5.34 POINT (431630 5343230) #> 8  existing  9.420000     89.6 3.63 POINT (436510 5340870) #> 9  existing  9.059999     65.1 4.80 POINT (435990 5339950) #> 10 existing  8.170000     93.5 3.38 POINT (438250 5337770)  calculate_ahels(   mraster = mr[[1:3]],   existing = e,   nQuant = 20,   nSamp = 300,   filename = tempfile(fileext = \".shp\") ) #> Creating covariance matrix. #>    |                                                                       |                                                              |   0%   |                                                                       |                                                              |   1%   |                                                                       |=                                                             |   1%   |                                                                       |=                                                             |   2%   |                                                                       |==                                                            |   2%   |                                                                       |==                                                            |   3%   |                                                                       |==                                                            |   4%   |                                                                       |===                                                           |   4%   |                                                                       |===                                                           |   5%   |                                                                       |===                                                           |   6%   |                                                                       |====                                                          |   6%   |                                                                       |====                                                          |   7%   |                                                                       |=====                                                         |   7%   |                                                                       |=====                                                         |   8%   |                                                                       |=====                                                         |   9%   |                                                                       |======                                                        |   9%   |                                                                       |======                                                        |  10%   |                                                                       |=======                                                       |  10%   |                                                                       |=======                                                       |  11%   |                                                                       |=======                                                       |  12%   |                                                                       |========                                                      |  12%   |                                                                       |========                                                      |  13%   |                                                                       |========                                                      |  14%   |                                                                       |=========                                                     |  14%   |                                                                       |=========                                                     |  15%   |                                                                       |==========                                                    |  15%   |                                                                       |==========                                                    |  16%   |                                                                       |==========                                                    |  17%   |                                                                       |===========                                                   |  17%   |                                                                       |===========                                                   |  18%   |                                                                       |===========                                                   |  19%   |                                                                       |============                                                  |  19%   |                                                                       |============                                                  |  20%   |                                                                       |=============                                                 |  20%   |                                                                       |=============                                                 |  21%   |                                                                       |=============                                                 |  22%   |                                                                       |==============                                                |  22%   |                                                                       |==============                                                |  23%   |                                                                       |===============                                               |  23%   |                                                                       |===============                                               |  24%   |                                                                       |===============                                               |  25%   |                                                                       |================                                              |  25%   |                                                                       |================                                              |  26%   |                                                                       |================                                              |  27%   |                                                                       |=================                                             |  27%   |                                                                       |=================                                             |  28%   |                                                                       |==================                                            |  28%   |                                                                       |==================                                            |  29%   |                                                                       |==================                                            |  30%   |                                                                       |===================                                           |  30%   |                                                                       |===================                                           |  31%   |                                                                       |====================                                          |  31%   |                                                                       |====================                                          |  32%   |                                                                       |====================                                          |  33%   |                                                                       |=====================                                         |  33%   |                                                                       |=====================                                         |  34%   |                                                                       |=====================                                         |  35%   |                                                                       |======================                                        |  35%   |                                                                       |======================                                        |  36%   |                                                                       |=======================                                       |  36%   |                                                                       |=======================                                       |  37%   |                                                                       |=======================                                       |  38%   |                                                                       |========================                                      |  38%   |                                                                       |========================                                      |  39%   |                                                                       |========================                                      |  40%   |                                                                       |=========================                                     |  40%   |                                                                       |=========================                                     |  41%   |                                                                       |==========================                                    |  41%   |                                                                       |==========================                                    |  42%   |                                                                       |==========================                                    |  43%   |                                                                       |===========================                                   |  43%   |                                                                       |===========================                                   |  44%   |                                                                       |============================                                  |  44%   |                                                                       |============================                                  |  45%   |                                                                       |============================                                  |  46%   |                                                                       |=============================                                 |  46%   |                                                                       |=============================                                 |  47%   |                                                                       |=============================                                 |  48%   |                                                                       |==============================                                |  48%   |                                                                       |==============================                                |  49%   |                                                                       |===============================                               |  49%   |                                                                       |===============================                               |  50%   |                                                                       |===============================                               |  51%   |                                                                       |================================                              |  51%   |                                                                       |================================                              |  52%   |                                                                       |=================================                             |  52%   |                                                                       |=================================                             |  53%   |                                                                       |=================================                             |  54%   |                                                                       |==================================                            |  54%   |                                                                       |==================================                            |  55%   |                                                                       |==================================                            |  56%   |                                                                       |===================================                           |  56%   |                                                                       |===================================                           |  57%   |                                                                       |====================================                          |  57%   |                                                                       |====================================                          |  58%   |                                                                       |====================================                          |  59%   |                                                                       |=====================================                         |  59%   |                                                                       |=====================================                         |  60%   |                                                                       |======================================                        |  60%   |                                                                       |======================================                        |  61%   |                                                                       |======================================                        |  62%   |                                                                       |=======================================                       |  62%   |                                                                       |=======================================                       |  63%   |                                                                       |=======================================                       |  64%   |                                                                       |========================================                      |  64%   |                                                                       |========================================                      |  65%   |                                                                       |=========================================                     |  65%   |                                                                       |=========================================                     |  66%   |                                                                       |=========================================                     |  67%   |                                                                       |==========================================                    |  67%   |                                                                       |==========================================                    |  68%   |                                                                       |==========================================                    |  69%   |                                                                       |===========================================                   |  69%   |                                                                       |===========================================                   |  70%   |                                                                       |============================================                  |  70%   |                                                                       |============================================                  |  71%   |                                                                       |============================================                  |  72%   |                                                                       |=============================================                 |  72%   |                                                                       |=============================================                 |  73%   |                                                                       |==============================================                |  73%   |                                                                       |==============================================                |  74%   |                                                                       |==============================================                |  75%   |                                                                       |===============================================               |  75%   |                                                                       |===============================================               |  76%   |                                                                       |===============================================               |  77%   |                                                                       |================================================              |  77%   |                                                                       |================================================              |  78%   |                                                                       |=================================================             |  78%   |                                                                       |=================================================             |  79%   |                                                                       |=================================================             |  80%   |                                                                       |==================================================            |  80%   |                                                                       |==================================================            |  81%   |                                                                       |===================================================           |  81%   |                                                                       |===================================================           |  82%   |                                                                       |===================================================           |  83%   |                                                                       |====================================================          |  83%   |                                                                       |====================================================          |  84%   |                                                                       |====================================================          |  85%   |                                                                       |=====================================================         |  85%   |                                                                       |=====================================================         |  86%   |                                                                       |======================================================        |  86%   |                                                                       |======================================================        |  87%   |                                                                       |======================================================        |  88%   |                                                                       |=======================================================       |  88%   |                                                                       |=======================================================       |  89%   |                                                                       |=======================================================       |  90%   |                                                                       |========================================================      |  90%   |                                                                       |========================================================      |  91%   |                                                                       |=========================================================     |  91%   |                                                                       |=========================================================     |  92%   |                                                                       |=========================================================     |  93%   |                                                                       |==========================================================    |  93%   |                                                                       |==========================================================    |  94%   |                                                                       |===========================================================   |  94%   |                                                                       |===========================================================   |  95%   |                                                                       |===========================================================   |  96%   |                                                                       |============================================================  |  96%   |                                                                       |============================================================  |  97%   |                                                                       |============================================================  |  98%   |                                                                       |============================================================= |  98%   |                                                                       |============================================================= |  99%   |                                                                       |==============================================================|  99%   |                                                                       |==============================================================| 100% #> nSamp of 300 has been provided. Samples will be added until this number is reached #> Underrepresented Quantile 1 - A total of 8 samples have been allocated. #> Underrepresented Quantile 2 - A total of 3 samples have been allocated. #> Underrepresented Quantile 3 - A total of 4 samples have been allocated. #> Underrepresented Quantile 4 - A total of 2 samples have been allocated. #> Underrepresented Quantile 5 - A total of 2 samples have been allocated. #> Underrepresented Quantile 6 - A total of 2 samples have been allocated. #> Underrepresented Quantile 7 - A total of 2 samples have been allocated. #> Underrepresented Quantile 8 - A total of 2 samples have been allocated. #> Underrepresented Quantile 9 - A total of 2 samples have been allocated. #> Underrepresented Quantile 10 - A total of 3 samples have been allocated. #> Underrepresented Quantile 11 - A total of 6 samples have been allocated. #> Underrepresented Quantile 12 - A total of 5 samples have been allocated. #> Underrepresented Quantile 13 - A total of 4 samples have been allocated. #> Underrepresented Quantile 14 - A total of 2 samples have been allocated. #> Underrepresented Quantile 15 - A total of 1 samples have been allocated. #> Underrepresented Quantile 16 - A total of 3 samples have been allocated. #> Underrepresented Quantile 17 - A total of 10 samples have been allocated. #> Underrepresented Quantile 18 - A total of 4 samples have been allocated. #> Underrepresented Quantile 19 - A total of 1 samples have been allocated. #> Underrepresented Quantile 20 - A total of 2 samples have been allocated. #> Underrepresented Quantile 21 - A total of 3 samples have been allocated. #> Underrepresented Quantile 22 - A total of 2 samples have been allocated. #> Underrepresented Quantile 23 - A total of 3 samples have been allocated. #> Underrepresented Quantile 24 - A total of 1 samples have been allocated. #> Underrepresented Quantile 25 - A total of 2 samples have been allocated. #> Underrepresented Quantile 26 - A total of 4 samples have been allocated. #> Underrepresented Quantile 27 - A total of 1 samples have been allocated. #> Underrepresented Quantile 28 - A total of 2 samples have been allocated. #> Underrepresented Quantile 29 - A total of 3 samples have been allocated. #> Underrepresented Quantile 30 - A total of 1 samples have been allocated. #> Underrepresented Quantile 31 - A total of 6 samples have been allocated. #> Underrepresented Quantile 32 - A total of 1 samples have been allocated. #> Underrepresented Quantile 33 - A total of 6 samples have been allocated. #> Underrepresented Quantile 34 - A total of 8 samples have been allocated. #> Underrepresented Quantile 35 - A total of 1 samples have been allocated. #> Underrepresented Quantile 36 - A total of 1 samples have been allocated. #> Underrepresented Quantile 37 - A total of 1 samples have been allocated. #> Underrepresented Quantile 38 - A total of 3 samples have been allocated. #> Underrepresented Quantile 39 - A total of 4 samples have been allocated. #> Underrepresented Quantile 40 - A total of 1 samples have been allocated. #> Underrepresented Quantile 41 - A total of 1 samples have been allocated. #> Underrepresented Quantile 42 - A total of 4 samples have been allocated. #> Underrepresented Quantile 43 - A total of 4 samples have been allocated. #> Underrepresented Quantile 44 - A total of 2 samples have been allocated. #> Underrepresented Quantile 45 - A total of 3 samples have been allocated. #> Underrepresented Quantile 46 - A total of 2 samples have been allocated. #> Underrepresented Quantile 47 - A total of 2 samples have been allocated. #> Underrepresented Quantile 48 - A total of 4 samples have been allocated. #> Underrepresented Quantile 49 - A total of 2 samples have been allocated. #> Underrepresented Quantile 50 - A total of 1 samples have been allocated. #> Underrepresented Quantile 51 - A total of 5 samples have been allocated. #> Underrepresented Quantile 52 - A total of 4 samples have been allocated. #> Underrepresented Quantile 53 - A total of 1 samples have been allocated. #> Underrepresented Quantile 54 - A total of 2 samples have been allocated. #> Underrepresented Quantile 55 - A total of 8 samples have been allocated. #> Underrepresented Quantile 56 - A total of 1 samples have been allocated. #> Underrepresented Quantile 57 - A total of 2 samples have been allocated. #> Underrepresented Quantile 58 - A total of 3 samples have been allocated. #> Underrepresented Quantile 59 - A total of 1 samples have been allocated. #> Underrepresented Quantile 60 - A total of 3 samples have been allocated. #> Underrepresented Quantile 61 - A total of 4 samples have been allocated. #> Underrepresented Quantile 62 - A total of 2 samples have been allocated. #> Underrepresented Quantile 63 - A total of 7 samples have been allocated. #> Underrepresented Quantile 64 - A total of 1 samples have been allocated. #> Underrepresented Quantile 65 - A total of 4 samples have been allocated. #> Underrepresented Quantile 66 - A total of 3 samples have been allocated. #> Underrepresented Quantile 67 - A total of 5 samples have been allocated. #> Underrepresented Quantile 68 - A total of 2 samples have been allocated. #> Underrepresented Quantile 69 - A total of 2 samples have been allocated. #> Underrepresented Quantile 70 - A total of 4 samples have been allocated. #> Underrepresented Quantile 71 - A total of 2 samples have been allocated. #> Underrepresented Quantile 72 - A total of 1 samples have been allocated. #> Underrepresented Quantile 73 - A total of 3 samples have been allocated. #> Underrepresented Quantile 74 - A total of 6 samples have been allocated. #> Underrepresented Quantile 75 - A total of 1 samples have been allocated. #> Underrepresented Quantile 76 - A total of 1 samples have been allocated. #> Underrepresented Quantile 77 - A total of 4 samples have been allocated. #> Underrepresented Quantile 78 - A total of 1 samples have been allocated. #> Underrepresented Quantile 79 - A total of 3 samples have been allocated. #> Underrepresented Quantile 80 - A total of 1 samples have been allocated. #> Underrepresented Quantile 81 - A total of 6 samples have been allocated. #> Underrepresented Quantile 82 - A total of 1 samples have been allocated. #> Underrepresented Quantile 83 - A total of 5 samples have been allocated. #> Underrepresented Quantile 84 - A total of 2 samples have been allocated. #> Underrepresented Quantile 85 - A total of 2 samples have been allocated. #> Underrepresented Quantile 86 - A total of 3 samples have been allocated. #> Underrepresented Quantile 87 - A total of 1 samples have been allocated. #> Underrepresented Quantile 88 - A total of 2 samples have been allocated. #> Underrepresented Quantile 89 - A total of 3 samples have been allocated. #> Underrepresented Quantile 90 - A total of 2 samples have been allocated. #> Underrepresented Quantile 91 - A total of 5 samples have been allocated. #> Underrepresented Quantile 92 - A total of 1 samples have been allocated. #> Underrepresented Quantile 93 - A total of 2 samples have been allocated. #> Underrepresented Quantile 94 - A total of 1 samples have been allocated. #> Underrepresented Quantile 95 - A total of 1 samples have been allocated. #> Underrepresented Quantile 96 - A total of 4 samples have been allocated. #> Underrepresented Quantile 97 - A total of 1 samples have been allocated. #> Underrepresented Quantile 98 - A total of 2 samples have been allocated. #> Underrepresented Quantile 99 - A total of 2 samples have been allocated. #> Underrepresented Quantile 100 - A total of 2 samples have been allocated. #> Underrepresented Quantile 101 - A total of 2 samples have been allocated. #> Underrepresented Quantile 102 - A total of 3 samples have been allocated. #> Underrepresented Quantile 103 - A total of 2 samples have been allocated. #> Underrepresented Quantile 104 - A total of 1 samples have been allocated. #> Underrepresented Quantile 105 - A total of 6 samples have been allocated. #> Underrepresented Quantile 106 - A total of 4 samples have been allocated. #> A total of 300 new samples added #> Writing layer `file54b069622846' to data source  #>   `C:\\Users\\tgood.stu\\AppData\\Local\\Temp\\Rtmp0Uciba\\file54b069622846.shp' using driver `ESRI Shapefile' #> Writing 400 features with 4 fields and geometry type Point. #> Simple feature collection with 400 features and 4 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337710 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>        type     zmean pzabove2  zsd               geometry #> 1  existing 11.490000     79.7 4.96 POINT (434970 5343030) #> 2  existing 10.679999     91.9 3.90 POINT (435590 5340510) #> 3  existing  5.640000     24.8 4.23 POINT (434290 5338670) #> 4  existing  7.490000     38.5 3.61 POINT (435170 5340410) #> 5  existing  9.170000     69.4 4.20 POINT (437550 5340650) #> 6  existing 11.059999     79.8 5.30 POINT (435850 5340130) #> 7  existing  9.240000     74.8 5.34 POINT (431630 5343230) #> 8  existing  9.420000     89.6 3.63 POINT (436510 5340870) #> 9  existing  9.059999     65.1 4.80 POINT (435990 5339950) #> 10 existing  8.170000     93.5 3.38 POINT (438250 5337770)"},{"path":"/reference/calculate_allocation.html","id":null,"dir":"Reference","previous_headings":"","what":"Determine required samples in strata — calculate_allocation","title":"Determine required samples in strata — calculate_allocation","text":"Determine required samples strata","code":""},{"path":"/reference/calculate_allocation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Determine required samples in strata — calculate_allocation","text":"","code":"calculate_allocation(   sraster,   nSamp,   allocation = \"prop\",   mraster = NULL,   existing = NULL,   force = FALSE )"},{"path":"/reference/calculate_allocation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Determine required samples in strata — calculate_allocation","text":"sraster spatRaster. Stratification raster used sampling. nSamp Numeric. Number desired samples. allocation Character. Allocation algorithm used. Either prop (default) proportional allocation optim optimal allocation (equal sampling cost) equal equal number samples (defined nSamp)  strata. mraster spatRaster. ALS metric raster. Required allocation = optim. existing sf data.frame.  Existing plot network. force Logical. Default = FALSE - force nSamp exactly user defined value cases nSamp sraster strata count equally divisible. effect existing provided.","code":""},{"path":"/reference/calculate_allocation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determine required samples in strata — calculate_allocation","text":"data.frame : strata - Strata ID. total - Total samples allocated (positive) removed (negative). need - Total required samples per strata.","code":""},{"path":"/reference/calculate_allocation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Determine required samples in strata — calculate_allocation","text":"Determine many samples allocate within strata","code":""},{"path":"/reference/calculate_allocation.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Determine required samples in strata — calculate_allocation","text":"Gregoire, T.G., & Valentine, H.T. (2007). Sampling Strategies Natural Resources Environment (1st ed.).  Chapman Hall/CRC. https://doi.org/10.1201/9780203498880","code":""},{"path":[]},{"path":"/reference/calculate_allocation.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Determine required samples in strata — calculate_allocation","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/calculate_allocation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Determine required samples in strata — calculate_allocation","text":"","code":"#--- Load strata raster and existing samples---# r <- system.file(\"extdata\", \"kmeans.tif\", package = \"sgsR\") sr <- terra::rast(r)  e <- system.file(\"extdata\", \"existing.shp\", package = \"sgsR\") e <- sf::st_read(e) #> Reading layer `existing' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\existing.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 100 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           unknown  #--- perform grid sampling ---# calculate_allocation(   sraster = sr,   nSamp = 200 ) #> Implementing porportional allocation of samples #> nSamp of 200 is not perfectly divisible based on strata distribution. nSamp of 199 will be returned. Use \"force = TRUE\" to brute force to 200. #>    strata total #> 1       1    13 #> 2       2    29 #> 3       3    14 #> 4       4    21 #> 5       5    25 #> 6       6    24 #> 7       7    24 #> 8       8    16 #> 9       9    23 #> 10     10    10  calculate_allocation(   sraster = sr,   nSamp = 200,   force = TRUE ) #> Implementing porportional allocation of samples #> Forcing 200 total samples. #>    strata total #> 1       1    13 #> 2       2    29 #> 3       3    14 #> 4       4    21 #> 5       5    25 #> 6       6    24 #> 7       7    24 #> 8       8    16 #> 9       9    23 #> 10     10    11  #--- extract strata from existing samples ---# e.sr <- extract_strata(   sraster = sr,   existing = e )  calculate_allocation(   sraster = sr,   nSamp = 200,   existing = e.sr ) #> Implementing porportional allocation of samples #> nSamp of 200 is not perfectly divisible based on strata distribution. nSamp of 199 will be returned. Use \"force = TRUE\" to brute force to 200. #>    strata total need #> 1       1    11   13 #> 2       2    15   29 #> 3       3     2   14 #> 4       4    10   21 #> 5       5    10   25 #> 6       6    10   24 #> 7       7    12   24 #> 8       8     3   16 #> 9       9    18   23 #> 10     10     8   10  #--- Load mraster for optimal allocation ---# mr <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(mr)  calculate_allocation(   sraster = sr,   nSamp = 200,   existing = e.sr,   allocation = \"optim\",   mraster = mr$zq90,   force = TRUE ) #> Implementing optimal allocation of samples based on variability of 'zq90' #> Forcing 200 total samples. #>    strata total need #> 1       1    15   17 #> 2       2    17   31 #> 3       3     3   14 #> 4       4     6   17 #> 5       5     4   19 #> 6       6     7   21 #> 7       7    11   23 #> 8       8    10   23 #> 9       9    16   21 #> 10     10    11   13"},{"path":"/reference/calculate_coobs.html","id":null,"dir":"Reference","previous_headings":"","what":"coobs algorithm sampling — calculate_coobs","title":"coobs algorithm sampling — calculate_coobs","text":"Perform COunt OBServations (coobs) algorithm using existing site data raster metrics. algorithm aids user determining additional samples located comparing existing samples pixel associated covariates. output coobs raster used constrain clhs sampling areas underreprented.","code":""},{"path":"/reference/calculate_coobs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"coobs algorithm sampling — calculate_coobs","text":"","code":"calculate_coobs(   mraster,   existing,   cores = 1,   threshold = 0.95,   plot = FALSE,   details = FALSE,   filename = NULL,   overwrite = FALSE )"},{"path":"/reference/calculate_coobs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"coobs algorithm sampling — calculate_coobs","text":"mraster spatRaster. ALS metrics raster. Requires least 2 layers calculate covariance matrix existing sf. Samples resulting sample_* functions. cores Numeric. Number cores use parallel processing. default = 1 threshold Numeric. Proxy maximum pixel quantile avoid outliers. default = 0.95 plot Logical. Plots output strata raster visualized strata boundary dividers. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc.","code":""},{"path":"/reference/calculate_coobs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"coobs algorithm sampling — calculate_coobs","text":"output raster coobs classified coobs layers.","code":""},{"path":"/reference/calculate_coobs.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"coobs algorithm sampling — calculate_coobs","text":"Special thanks Dr. Brendan Malone original implementation algorithm.","code":""},{"path":"/reference/calculate_coobs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"coobs algorithm sampling — calculate_coobs","text":"Malone BP, Minansy B, Brungard C. 2019. methods improve utility conditioned Latin hypercube sampling. PeerJ 7:e6451 DOI 10.7717/peerj.6451","code":""},{"path":[]},{"path":"/reference/calculate_coobs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"coobs algorithm sampling — calculate_coobs","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/calculate_coobs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"coobs algorithm sampling — calculate_coobs","text":"","code":"if (FALSE) { #--- Load raster and existing plots---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  e <- system.file(\"extdata\", \"existing.shp\", package = \"sgsR\") e <- sf::st_read(e)  calculate_coobs(   mraster = mr,   existing = e,   cores = 4,   details = TRUE,   filename = tempfile(fileext = \".tif\") ) }"},{"path":"/reference/calculate_distance.html","id":null,"dir":"Reference","previous_headings":"","what":"Distance to access layer — calculate_distance","title":"Distance to access layer — calculate_distance","text":"Per pixel distance nearest access vector. Intended used `cost` constraint within sample_clhs function","code":""},{"path":"/reference/calculate_distance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Distance to access layer — calculate_distance","text":"","code":"calculate_distance(   raster,   access,   plot = FALSE,   filename = NULL,   overwrite = FALSE )"},{"path":"/reference/calculate_distance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Distance to access layer — calculate_distance","text":"raster spatRaster. Raster used calculate pixel level distance access layer. access sf. Road access network - must lines. plot Logical. Plots output strata raster samples. filename Character. Path write output samples. overwrite Logical. Choice overwrite existing filename exists.","code":""},{"path":"/reference/calculate_distance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Distance to access layer — calculate_distance","text":"Input raster dist2access layer appended.","code":""},{"path":[]},{"path":"/reference/calculate_distance.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Distance to access layer — calculate_distance","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/calculate_distance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Distance to access layer — calculate_distance","text":"","code":"#--- Load raster and access files ---# r <- system.file(\"extdata\", \"kmeans.tif\", package = \"sgsR\") sr <- terra::rast(r)  a <- system.file(\"extdata\", \"roads.shp\", package = \"sgsR\") ac <- sf::st_read(a) #> Reading layer `roads' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\roads.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 167 features and 2 fields #> Geometry type: MULTILINESTRING #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337700 xmax: 438560 ymax: 5343240 #> Projected CRS: UTM_Zone_17_Northern_Hemisphere  calculate_distance(   raster = sr,   access = ac,   plot = TRUE ) #> calculating per pixel distance to provided access layer #> class       : SpatRaster  #> dimensions  : 277, 373, 2  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> sources     : kmeans.tif   #>               memory   #> names       :      strata, dist2access  #> min values  : 1.000000000, 0.006621213  #> max values  :       10.00,     1061.66   calculate_distance(   raster = sr,   access = ac,   plot = TRUE,   filename = tempfile(fileext = \".tif\") ) #> calculating per pixel distance to provided access layer  #> class       : SpatRaster  #> dimensions  : 277, 373, 2  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> sources     : kmeans.tif   #>               memory   #> names       :      strata, dist2access  #> min values  : 1.000000000, 0.006621213  #> max values  :       10.00,     1061.66"},{"path":"/reference/calculate_lhsOpt.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze optimal Latin hypercube sample number — calculate_lhsOpt","title":"Analyze optimal Latin hypercube sample number — calculate_lhsOpt","text":"Population level analysis metric raster data determine optimal Latin Hypercube sample size","code":""},{"path":"/reference/calculate_lhsOpt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze optimal Latin hypercube sample number — calculate_lhsOpt","text":"","code":"calculate_lhsOpt(   popLHS,   PCA = TRUE,   quant = TRUE,   KLdiv = TRUE,   minSamp = 10,   maxSamp = 100,   step = 10,   rep = 10,   iter = 10000 )"},{"path":"/reference/calculate_lhsOpt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze optimal Latin hypercube sample number — calculate_lhsOpt","text":"popLHS List. Output calculate_lhsPop function. PCA Logical. Calculates principal component loadings population PCA similarity factor testing. default = TRUE. quant Logical. Calculates quantile matrix population quantile comparison testing. default = TRUE. KLdiv Logical. Calculates covariate matrix population Kullback–Leibler divergence testing. default = TRUE. Relies quant = TRUE calculate. minSamp Numeric. Minimum sample size test. default = 10. maxSamp Numeric. Maximum sample size test. default = 100. step Numeric. Sample step size iteration. default = 10. rep Numeric. Internal repetitions sample size. default = 10. iter Numeric. Internal clhs - positive number, giving number iterations Metropolis-Hastings annealing process. Defaults 10000.","code":""},{"path":"/reference/calculate_lhsOpt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze optimal Latin hypercube sample number — calculate_lhsOpt","text":"data.frame summary statistics.","code":""},{"path":"/reference/calculate_lhsOpt.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Analyze optimal Latin hypercube sample number — calculate_lhsOpt","text":"Special thanks Dr. Brendan Malone original implementation algorithm.","code":""},{"path":"/reference/calculate_lhsOpt.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Analyze optimal Latin hypercube sample number — calculate_lhsOpt","text":"Malone BP, Minansy B, Brungard C. 2019. methods improve utility conditioned Latin hypercube sampling. PeerJ 7:e6451 DOI 10.7717/peerj.6451","code":""},{"path":"/reference/calculate_lhsOpt.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Analyze optimal Latin hypercube sample number — calculate_lhsOpt","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/calculate_lhsOpt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyze optimal Latin hypercube sample number — calculate_lhsOpt","text":"","code":"if (FALSE) { #--- Load raster and access files ---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  #--- calculate lhsPop details ---# poplhs <- calculate_lhsPop(mraster = mr)  calculate_lhsOpt(popLHS = poplhs)  calculate_lhsOpt(   popLHS = poplhs,   PCA = FALSE,   iter = 200 ) }"},{"path":"/reference/calculate_lhsPop.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyze covariates for lhs — calculate_lhsPop","title":"Analyze covariates for lhs — calculate_lhsPop","text":"Population level analysis metric raster data Calculates population level statistics including principal components, quantile matrix, Kullback-leibler  divergence neccesary calculate_lhsOpt.","code":""},{"path":"/reference/calculate_lhsPop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyze covariates for lhs — calculate_lhsPop","text":"","code":"calculate_lhsPop(mraster, PCA = TRUE, quant = TRUE, nQuant = 10, KLdiv = TRUE)"},{"path":"/reference/calculate_lhsPop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyze covariates for lhs — calculate_lhsPop","text":"mraster spatRaster. ALS metrics raster. PCA Logical. Calculates principal component loadings population PCA similarity factor testing. default = TRUE. quant Logical. Calculates quantile matrix population quantile comparison testing. default = TRUE. nQuant Numeric. Number quantiles divide population quant. default = 10. KLdiv Logical. Calculates covariate matrix population Kullback–Leibler divergence testing. default = TRUE. Relies quant = TRUE calculate.","code":""},{"path":"/reference/calculate_lhsPop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Analyze covariates for lhs — calculate_lhsPop","text":"List matrices used input calculate_lhsOpt.","code":""},{"path":"/reference/calculate_lhsPop.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Analyze covariates for lhs — calculate_lhsPop","text":"Special thanks Dr. Brendan Malone original implementation algorithm.","code":""},{"path":"/reference/calculate_lhsPop.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Analyze covariates for lhs — calculate_lhsPop","text":"Malone BP, Minansy B, Brungard C. 2019. methods improve utility conditioned Latin hypercube sampling. PeerJ 7:e6451 DOI 10.7717/peerj.6451","code":""},{"path":[]},{"path":"/reference/calculate_lhsPop.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Analyze covariates for lhs — calculate_lhsPop","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/calculate_lhsPop.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyze covariates for lhs — calculate_lhsPop","text":"","code":"if (FALSE) { #--- Load raster and access files ---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  calculate_lhsPop(mraster = mr)  calculate_lhsPop(   mraster = mr,   nQuant = 10,   PCA = FALSE ) }"},{"path":"/reference/calculate_pcomp.html","id":null,"dir":"Reference","previous_headings":"","what":"Raster principal components — calculate_pcomp","title":"Raster principal components — calculate_pcomp","text":"Calculate rasterize principal components metric raster","code":""},{"path":"/reference/calculate_pcomp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Raster principal components — calculate_pcomp","text":"","code":"calculate_pcomp(   mraster,   nComp,   center = TRUE,   scale = TRUE,   plot = FALSE,   details = FALSE,   filename = NULL,   overwrite = FALSE,   ... )"},{"path":"/reference/calculate_pcomp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Raster principal components — calculate_pcomp","text":"mraster spatRaster. ALS metrics raster. nComp Numeric. Value indicating number principal components rasterized. prior analysis. center Logical. Value indicating whether variables shifted zero centered. scale Logical. Value indicating whether variables scaled unit variance plot Logical. Plots output strata raster samples. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. filename Character. Path write output samples. overwrite Logical. Choice overwrite existing filename exists. ... Additional arguments passed prcomp.","code":""},{"path":"/reference/calculate_pcomp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Raster principal components — calculate_pcomp","text":"Output raster specified number principal components layers.","code":""},{"path":[]},{"path":"/reference/calculate_pcomp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Raster principal components — calculate_pcomp","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/calculate_pcomp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Raster principal components — calculate_pcomp","text":"","code":"#--- Load raster ---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  calculate_pcomp(   mraster = mr,   nComp = 5,   plot = TRUE )  #> class       : SpatRaster  #> dimensions  : 277, 373, 5  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> sources     : memory   #>               memory   #>               memory   #>               ... and 2 more source(s) #> names       :        PC1,        PC2,        PC3,        PC4,        PC5  #> min values  : -5.8417985, -6.3694763, -4.0382460, -2.4972669, -0.6925408  #> max values  :   7.806999,   2.565417,   1.633358,   1.598260,   1.530968   pcomp <- calculate_pcomp(            mraster = mr,            nComp = 3,            details = TRUE          )  #--- Display principal component details ---# pcomp$pca #> Standard deviations (1, .., p=7): #> [1] 2.39419952 0.86117918 0.65363319 0.27246138 0.11007946 0.10828637 #> [7] 0.02939539 #>  #> Rotation (n x k) = (7 x 7): #>                PC1         PC2         PC3         PC4         PC5 #> zmean    0.4133334  0.09704163 -0.16917057  0.05440712 -0.22000532 #> pzabove2 0.3217923  0.28576528  0.89947768  0.04709941  0.05904585 #> zsd      0.3314081 -0.70019069  0.06653226 -0.06472512  0.60973701 #> zq20     0.3511220  0.56046214 -0.30856343 -0.47873324  0.46460623 #> zq50     0.4055034  0.12095230 -0.21088469  0.55460643 -0.05871399 #> zq70     0.4116791 -0.07297959 -0.13368861  0.36832636 -0.08204398 #> zq90     0.3982141 -0.29082785  0.01839257 -0.56408691 -0.59185684 #>                   PC6          PC7 #> zmean     0.052917370  0.858462025 #> pzabove2 -0.004146026  0.002415685 #> zsd      -0.098391685  0.099124286 #> zq20      0.032759647 -0.145830192 #> zq50     -0.629977381 -0.261835891 #> zq70      0.755333726 -0.307241076 #> zq90     -0.137941678 -0.262659351  #--- Display importance of components ---# summary(pcomp$pca) #> Importance of components: #>                           PC1    PC2     PC3     PC4     PC5     PC6 #> Standard deviation     2.3942 0.8612 0.65363 0.27246 0.11008 0.10829 #> Proportion of Variance 0.8189 0.1060 0.06103 0.01061 0.00173 0.00168 #> Cumulative Proportion  0.8189 0.9248 0.98587 0.99647 0.99820 0.99988 #>                            PC7 #> Standard deviation     0.02940 #> Proportion of Variance 0.00012 #> Cumulative Proportion  1.00000"},{"path":"/reference/calculate_sampsize.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample size determination — calculate_sampsize","title":"Sample size determination — calculate_sampsize","text":"Determine samples size simple random sampling using relative standard error","code":""},{"path":"/reference/calculate_sampsize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample size determination — calculate_sampsize","text":"","code":"calculate_sampsize(   mraster,   rse = NULL,   start = 0.01,   end = 0.05,   increment = 0.001,   plot = FALSE )"},{"path":"/reference/calculate_sampsize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample size determination — calculate_sampsize","text":"mraster spatRaster. Metrics raster. values must numeric. rse Numeric. Desired relative standard error (coefficient variation mean) threshold determine sample size. start Numeric. First rse value begin rse sequence. default = 0.01. end Numeric. Final rse value end rse sequence. default = 0.05. increment Numeric. Value increment start & end. default = 0.001. plot Logical. TRUE output graphical representation estimated sample size vs. rse.","code":""},{"path":"/reference/calculate_sampsize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample size determination — calculate_sampsize","text":"data.frame sample size rse raster variable.","code":""},{"path":"/reference/calculate_sampsize.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sample size determination — calculate_sampsize","text":"$$rse = (100 * SE) / mean)$$ : SE - Standard error mean s - Standard deviation observations n - Number observations","code":""},{"path":"/reference/calculate_sampsize.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Sample size determination — calculate_sampsize","text":"Benedetti, R., Piersimoni, F., & Postiglione, P. (2015).  Sampling spatial units agricultural surveys. pp 202-203. Berlin: Springer.","code":""},{"path":[]},{"path":"/reference/calculate_sampsize.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Sample size determination — calculate_sampsize","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/calculate_sampsize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sample size determination — calculate_sampsize","text":"","code":"#--- Load raster ---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  calculate_sampsize(mraster = mr,                    rse = 0.01,                    plot = TRUE) #> $nSamp #>   nSamp  rse      var #> 1  2030 0.01    zmean #> 2  1341 0.01 pzabove2 #> 3  1859 0.01      zsd #> 4  3647 0.01     zq20 #> 5  2581 0.01     zq50 #> 6  2110 0.01     zq70 #> 7  1394 0.01     zq90 #>  #> $plot  #>                      calculate_sampsize(mraster = mr,                    plot = TRUE) #> $nSamp #>     nSamp   rse      var #> 1    2030 0.010    zmean #> 2    1684 0.011    zmean #> 3    1419 0.012    zmean #> 4    1212 0.013    zmean #> 5    1047 0.014    zmean #> 6     914 0.015    zmean #> 7     804 0.016    zmean #> 8     713 0.017    zmean #> 9     637 0.018    zmean #> 10    572 0.019    zmean #> 11    516 0.020    zmean #> 12    469 0.021    zmean #> 13    427 0.022    zmean #> 14    391 0.023    zmean #> 15    359 0.024    zmean #> 16    331 0.025    zmean #> 17    306 0.026    zmean #> 18    284 0.027    zmean #> 19    264 0.028    zmean #> 20    247 0.029    zmean #> 21    230 0.030    zmean #> 22    216 0.031    zmean #> 23    203 0.032    zmean #> 24    191 0.033    zmean #> 25    180 0.034    zmean #> 26    170 0.035    zmean #> 27    160 0.036    zmean #> 28    152 0.037    zmean #> 29    144 0.038    zmean #> 30    137 0.039    zmean #> 31    130 0.040    zmean #> 32    124 0.041    zmean #> 33    118 0.042    zmean #> 34    113 0.043    zmean #> 35    108 0.044    zmean #> 36    103 0.045    zmean #> 37     98 0.046    zmean #> 38     94 0.047    zmean #> 39     90 0.048    zmean #> 40     87 0.049    zmean #> 41     83 0.050    zmean #> 42   1341 0.010 pzabove2 #> 43   1111 0.011 pzabove2 #> 44    935 0.012 pzabove2 #> 45    798 0.013 pzabove2 #> 46    689 0.014 pzabove2 #> 47    601 0.015 pzabove2 #> 48    529 0.016 pzabove2 #> 49    469 0.017 pzabove2 #> 50    418 0.018 pzabove2 #> 51    376 0.019 pzabove2 #> 52    339 0.020 pzabove2 #> 53    308 0.021 pzabove2 #> 54    281 0.022 pzabove2 #> 55    257 0.023 pzabove2 #> 56    236 0.024 pzabove2 #> 57    218 0.025 pzabove2 #> 58    201 0.026 pzabove2 #> 59    187 0.027 pzabove2 #> 60    174 0.028 pzabove2 #> 61    162 0.029 pzabove2 #> 62    151 0.030 pzabove2 #> 63    142 0.031 pzabove2 #> 64    133 0.032 pzabove2 #> 65    125 0.033 pzabove2 #> 66    118 0.034 pzabove2 #> 67    111 0.035 pzabove2 #> 68    105 0.036 pzabove2 #> 69    100 0.037 pzabove2 #> 70     95 0.038 pzabove2 #> 71     90 0.039 pzabove2 #> 72     85 0.040 pzabove2 #> 73     81 0.041 pzabove2 #> 74     78 0.042 pzabove2 #> 75     74 0.043 pzabove2 #> 76     71 0.044 pzabove2 #> 77     68 0.045 pzabove2 #> 78     65 0.046 pzabove2 #> 79     62 0.047 pzabove2 #> 80     59 0.048 pzabove2 #> 81     57 0.049 pzabove2 #> 82     55 0.050 pzabove2 #> 83   1859 0.010      zsd #> 84   1542 0.011      zsd #> 85   1299 0.012      zsd #> 86   1109 0.013      zsd #> 87    958 0.014      zsd #> 88    836 0.015      zsd #> 89    735 0.016      zsd #> 90    652 0.017      zsd #> 91    582 0.018      zsd #> 92    523 0.019      zsd #> 93    472 0.020      zsd #> 94    429 0.021      zsd #> 95    391 0.022      zsd #> 96    358 0.023      zsd #> 97    329 0.024      zsd #> 98    303 0.025      zsd #> 99    280 0.026      zsd #> 100   260 0.027      zsd #> 101   242 0.028      zsd #> 102   225 0.029      zsd #> 103   211 0.030      zsd #> 104   197 0.031      zsd #> 105   185 0.032      zsd #> 106   174 0.033      zsd #> 107   164 0.034      zsd #> 108   155 0.035      zsd #> 109   147 0.036      zsd #> 110   139 0.037      zsd #> 111   132 0.038      zsd #> 112   125 0.039      zsd #> 113   119 0.040      zsd #> 114   113 0.041      zsd #> 115   108 0.042      zsd #> 116   103 0.043      zsd #> 117    98 0.044      zsd #> 118    94 0.045      zsd #> 119    90 0.046      zsd #> 120    86 0.047      zsd #> 121    83 0.048      zsd #> 122    79 0.049      zsd #> 123    76 0.050      zsd #> 124  3647 0.010     zq20 #> 125  3035 0.011     zq20 #> 126  2564 0.012     zq20 #> 127  2194 0.013     zq20 #> 128  1898 0.014     zq20 #> 129  1658 0.015     zq20 #> 130  1460 0.016     zq20 #> 131  1296 0.017     zq20 #> 132  1158 0.018     zq20 #> 133  1041 0.019     zq20 #> 134   940 0.020     zq20 #> 135   854 0.021     zq20 #> 136   779 0.022     zq20 #> 137   713 0.023     zq20 #> 138   655 0.024     zq20 #> 139   604 0.025     zq20 #> 140   559 0.026     zq20 #> 141   519 0.027     zq20 #> 142   482 0.028     zq20 #> 143   450 0.029     zq20 #> 144   421 0.030     zq20 #> 145   394 0.031     zq20 #> 146   370 0.032     zq20 #> 147   348 0.033     zq20 #> 148   328 0.034     zq20 #> 149   310 0.035     zq20 #> 150   293 0.036     zq20 #> 151   277 0.037     zq20 #> 152   263 0.038     zq20 #> 153   250 0.039     zq20 #> 154   237 0.040     zq20 #> 155   226 0.041     zq20 #> 156   215 0.042     zq20 #> 157   205 0.043     zq20 #> 158   196 0.044     zq20 #> 159   188 0.045     zq20 #> 160   180 0.046     zq20 #> 161   172 0.047     zq20 #> 162   165 0.048     zq20 #> 163   158 0.049     zq20 #> 164   152 0.050     zq20 #> 165  2581 0.010     zq50 #> 166  2144 0.011     zq50 #> 167  1808 0.012     zq50 #> 168  1546 0.013     zq50 #> 169  1336 0.014     zq50 #> 170  1166 0.015     zq50 #> 171  1026 0.016     zq50 #> 172   910 0.017     zq50 #> 173   813 0.018     zq50 #> 174   730 0.019     zq50 #> 175   660 0.020     zq50 #> 176   599 0.021     zq50 #> 177   546 0.022     zq50 #> 178   500 0.023     zq50 #> 179   459 0.024     zq50 #> 180   424 0.025     zq50 #> 181   392 0.026     zq50 #> 182   363 0.027     zq50 #> 183   338 0.028     zq50 #> 184   315 0.029     zq50 #> 185   295 0.030     zq50 #> 186   276 0.031     zq50 #> 187   259 0.032     zq50 #> 188   244 0.033     zq50 #> 189   230 0.034     zq50 #> 190   217 0.035     zq50 #> 191   205 0.036     zq50 #> 192   194 0.037     zq50 #> 193   184 0.038     zq50 #> 194   175 0.039     zq50 #> 195   166 0.040     zq50 #> 196   158 0.041     zq50 #> 197   151 0.042     zq50 #> 198   144 0.043     zq50 #> 199   137 0.044     zq50 #> 200   131 0.045     zq50 #> 201   126 0.046     zq50 #> 202   121 0.047     zq50 #> 203   116 0.048     zq50 #> 204   111 0.049     zq50 #> 205   107 0.050     zq50 #> 206  2110 0.010     zq70 #> 207  1751 0.011     zq70 #> 208  1476 0.012     zq70 #> 209  1261 0.013     zq70 #> 210  1089 0.014     zq70 #> 211   950 0.015     zq70 #> 212   836 0.016     zq70 #> 213   742 0.017     zq70 #> 214   662 0.018     zq70 #> 215   595 0.019     zq70 #> 216   537 0.020     zq70 #> 217   488 0.021     zq70 #> 218   445 0.022     zq70 #> 219   407 0.023     zq70 #> 220   374 0.024     zq70 #> 221   345 0.025     zq70 #> 222   319 0.026     zq70 #> 223   296 0.027     zq70 #> 224   275 0.028     zq70 #> 225   257 0.029     zq70 #> 226   240 0.030     zq70 #> 227   225 0.031     zq70 #> 228   211 0.032     zq70 #> 229   198 0.033     zq70 #> 230   187 0.034     zq70 #> 231   176 0.035     zq70 #> 232   167 0.036     zq70 #> 233   158 0.037     zq70 #> 234   150 0.038     zq70 #> 235   142 0.039     zq70 #> 236   135 0.040     zq70 #> 237   129 0.041     zq70 #> 238   123 0.042     zq70 #> 239   117 0.043     zq70 #> 240   112 0.044     zq70 #> 241   107 0.045     zq70 #> 242   102 0.046     zq70 #> 243    98 0.047     zq70 #> 244    94 0.048     zq70 #> 245    90 0.049     zq70 #> 246    87 0.050     zq70 #> 247  1394 0.010     zq90 #> 248  1155 0.011     zq90 #> 249   973 0.012     zq90 #> 250   830 0.013     zq90 #> 251   717 0.014     zq90 #> 252   625 0.015     zq90 #> 253   550 0.016     zq90 #> 254   488 0.017     zq90 #> 255   435 0.018     zq90 #> 256   391 0.019     zq90 #> 257   353 0.020     zq90 #> 258   320 0.021     zq90 #> 259   292 0.022     zq90 #> 260   267 0.023     zq90 #> 261   246 0.024     zq90 #> 262   226 0.025     zq90 #> 263   209 0.026     zq90 #> 264   194 0.027     zq90 #> 265   181 0.028     zq90 #> 266   168 0.029     zq90 #> 267   157 0.030     zq90 #> 268   148 0.031     zq90 #> 269   138 0.032     zq90 #> 270   130 0.033     zq90 #> 271   123 0.034     zq90 #> 272   116 0.035     zq90 #> 273   110 0.036     zq90 #> 274   104 0.037     zq90 #> 275    98 0.038     zq90 #> 276    93 0.039     zq90 #> 277    89 0.040     zq90 #> 278    85 0.041     zq90 #> 279    81 0.042     zq90 #> 280    77 0.043     zq90 #> 281    74 0.044     zq90 #> 282    70 0.045     zq90 #> 283    67 0.046     zq90 #> 284    65 0.047     zq90 #> 285    62 0.048     zq90 #> 286    59 0.049     zq90 #> 287    57 0.050     zq90 #>  #> $plot  #>                      calculate_sampsize(mraster = mr,                    rse = 0.025,                    start = 0.01,                    end = 0.08,                    increment = 0.01,                    plot = TRUE) #> 'rse' not perfectly divisible by 'incremenent.  #> Selecting closest sample size (rse = 0.03) based on values. #> $nSamp #> # A tibble: 7 x 3 #> # Groups:   var [7] #>   nSamp   rse var      #>   <dbl> <dbl> <chr>    #> 1   230  0.03 zmean    #> 2   151  0.03 pzabove2 #> 3   211  0.03 zsd      #> 4   421  0.03 zq20     #> 5   295  0.03 zq50     #> 6   240  0.03 zq70     #> 7   157  0.03 zq90     #>  #> $plot  #>                      #--- higher variance leads to need for more samples ---#"},{"path":"/reference/extract.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract — extract","title":"Extract — extract","text":"Extract raster values samples Extract metric raster attributes existing","code":""},{"path":"/reference/extract.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract — extract","text":"","code":"extract_strata(   sraster,   existing,   data.frame = FALSE,   filename = NULL,   overwrite = FALSE )  extract_metrics(   mraster,   existing,   data.frame = FALSE,   filename = NULL,   overwrite = FALSE )"},{"path":"/reference/extract.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract — extract","text":"sraster spatRaster. Stratification raster. existing sf. Samples resulting sample_* functions. data.frame Logical. true outputs data.frame filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc. mraster Spatraster. Primary covariate raster stratify.","code":""},{"path":"/reference/extract.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract — extract","text":"sf data.frame object samples strata attributes sf data.frame object samples associated raster cell attributes","code":""},{"path":"/reference/masking.html","id":null,"dir":"Reference","previous_headings":"","what":"Masking — masking","title":"Masking — masking","text":"Create covariate sample matrices","code":""},{"path":"/reference/masking.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Masking — masking","text":"","code":"mask_access(raster, access, buff_inner, buff_outer)"},{"path":"/reference/masking.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Masking — masking","text":"raster SpatRaster. Raster masked. access sf. Road access network - must lines. buff_inner Numeric. Inner buffer boundary specifying distance access plots sampled. buff_outer Numeric. Outer buffer boundary specifying distance access plots can sampled.","code":""},{"path":"/reference/matrices.html","id":null,"dir":"Reference","previous_headings":"","what":"Matrices — matrices","title":"Matrices — matrices","text":"Create covariate sample matrices","code":""},{"path":"/reference/matrices.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Matrices — matrices","text":"","code":"mat_quant(vals, nQuant, nb)  mat_cov(vals, nQuant, nb, matQ)  mat_covNB(vals, nQuant, nb, matQ)"},{"path":"/reference/matrices.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Matrices — matrices","text":"vals Covariate / sample data nQuant Number quantiles nb Number bands matQ Quantile matrix","code":""},{"path":"/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling `rhs(lhs)`.","code":""},{"path":"/reference/plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot — plot","title":"Plot — plot","text":"Plot Class Plot","code":""},{"path":"/reference/plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot — plot","text":"","code":"classPlot(dfc, coordsgrps, mraster, mraster2, samp)"},{"path":"/reference/plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot — plot","text":"dfc data.frame. Values mraster mraster2 coordsgrps List. Cartesian coordinates strata mraster Spatraster. Primary covariate raster stratify. mraster2 Spatraster. Secondary covariate raster stratify. samp Numeric. Determines proportion cells plot","code":""},{"path":"/reference/sample_ahels.html","id":null,"dir":"Reference","previous_headings":"","what":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — sample_ahels","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — sample_ahels","text":"Perform adapted Hypercube Evaluation Legacy Sample (ahels) algorithm using existing site data raster metrics. New samples allocated based quantile ratios existing sample covariate dataset.","code":""},{"path":"/reference/sample_ahels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — sample_ahels","text":"","code":"sample_ahels(   mraster,   existing,   nQuant = 10,   nSamp = NULL,   threshold = 0.9,   plot = FALSE,   details = FALSE,   filename = NULL,   overwrite = FALSE )"},{"path":"/reference/sample_ahels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — sample_ahels","text":"mraster spatRaster. ALS metrics raster. existing sf. Samples resulting sample_* functions. nQuant Numeric. Number quantiles divide covariates samples . Quantiles cover least 1 percent area interest excluded returned NA. nSamp Numeric. Maximum number new samples allocate. provided, algorithm default allocating number samples provided. threshold Numeric. sample quantile ratio threshold establishing whether additional samples added. default = 0.9. Values close 1 can cause algorithm continually loop used sparingly. plot Logial. Plots existing (circles) new (crosses) samples first band mraster. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc.","code":""},{"path":"/reference/sample_ahels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — sample_ahels","text":"Returns sf point object existing samples supplemental samples added ahels algorithm.","code":""},{"path":"/reference/sample_ahels.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — sample_ahels","text":"Special thanks Dr. Brendan Malone original implementation algorithm.","code":""},{"path":"/reference/sample_ahels.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — sample_ahels","text":"Malone BP, Minansy B, Brungard C. 2019. methods improve utility conditioned Latin hypercube sampling. PeerJ 7:e6451 DOI 10.7717/peerj.6451","code":""},{"path":[]},{"path":"/reference/sample_ahels.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — sample_ahels","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/sample_ahels.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adapted Hypercube Evaluation of a Legacy Sample (ahels) — sample_ahels","text":"","code":"#--- Load raster and existing plots---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  e <- system.file(\"extdata\", \"existing.shp\", package = \"sgsR\") e <- sf::st_read(e) #> Reading layer `existing' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\existing.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 100 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           unknown  sample_ahels(   mraster = mr[[1:3]],   existing = e,   plot = TRUE ) #> Creating covariance matrix. #>    |                                                                       |                                                              |   0%   |                                                                       |                                                              |   1%   |                                                                       |=                                                             |   1%   |                                                                       |=                                                             |   2%   |                                                                       |==                                                            |   2%   |                                                                       |==                                                            |   3%   |                                                                       |==                                                            |   4%   |                                                                       |===                                                           |   4%   |                                                                       |===                                                           |   5%   |                                                                       |===                                                           |   6%   |                                                                       |====                                                          |   6%   |                                                                       |====                                                          |   7%   |                                                                       |=====                                                         |   7%   |                                                                       |=====                                                         |   8%   |                                                                       |=====                                                         |   9%   |                                                                       |======                                                        |   9%   |                                                                       |======                                                        |  10%   |                                                                       |=======                                                       |  10%   |                                                                       |=======                                                       |  11%   |                                                                       |=======                                                       |  12%   |                                                                       |========                                                      |  12%   |                                                                       |========                                                      |  13%   |                                                                       |========                                                      |  14%   |                                                                       |=========                                                     |  14%   |                                                                       |=========                                                     |  15%   |                                                                       |==========                                                    |  15%   |                                                                       |==========                                                    |  16%   |                                                                       |==========                                                    |  17%   |                                                                       |===========                                                   |  17%   |                                                                       |===========                                                   |  18%   |                                                                       |===========                                                   |  19%   |                                                                       |============                                                  |  19%   |                                                                       |============                                                  |  20%   |                                                                       |=============                                                 |  20%   |                                                                       |=============                                                 |  21%   |                                                                       |=============                                                 |  22%   |                                                                       |==============                                                |  22%   |                                                                       |==============                                                |  23%   |                                                                       |===============                                               |  23%   |                                                                       |===============                                               |  24%   |                                                                       |===============                                               |  25%   |                                                                       |================                                              |  25%   |                                                                       |================                                              |  26%   |                                                                       |================                                              |  27%   |                                                                       |=================                                             |  27%   |                                                                       |=================                                             |  28%   |                                                                       |==================                                            |  28%   |                                                                       |==================                                            |  29%   |                                                                       |==================                                            |  30%   |                                                                       |===================                                           |  30%   |                                                                       |===================                                           |  31%   |                                                                       |====================                                          |  31%   |                                                                       |====================                                          |  32%   |                                                                       |====================                                          |  33%   |                                                                       |=====================                                         |  33%   |                                                                       |=====================                                         |  34%   |                                                                       |=====================                                         |  35%   |                                                                       |======================                                        |  35%   |                                                                       |======================                                        |  36%   |                                                                       |=======================                                       |  36%   |                                                                       |=======================                                       |  37%   |                                                                       |=======================                                       |  38%   |                                                                       |========================                                      |  38%   |                                                                       |========================                                      |  39%   |                                                                       |========================                                      |  40%   |                                                                       |=========================                                     |  40%   |                                                                       |=========================                                     |  41%   |                                                                       |==========================                                    |  41%   |                                                                       |==========================                                    |  42%   |                                                                       |==========================                                    |  43%   |                                                                       |===========================                                   |  43%   |                                                                       |===========================                                   |  44%   |                                                                       |============================                                  |  44%   |                                                                       |============================                                  |  45%   |                                                                       |============================                                  |  46%   |                                                                       |=============================                                 |  46%   |                                                                       |=============================                                 |  47%   |                                                                       |=============================                                 |  48%   |                                                                       |==============================                                |  48%   |                                                                       |==============================                                |  49%   |                                                                       |===============================                               |  49%   |                                                                       |===============================                               |  50%   |                                                                       |===============================                               |  51%   |                                                                       |================================                              |  51%   |                                                                       |================================                              |  52%   |                                                                       |=================================                             |  52%   |                                                                       |=================================                             |  53%   |                                                                       |=================================                             |  54%   |                                                                       |==================================                            |  54%   |                                                                       |==================================                            |  55%   |                                                                       |==================================                            |  56%   |                                                                       |===================================                           |  56%   |                                                                       |===================================                           |  57%   |                                                                       |====================================                          |  57%   |                                                                       |====================================                          |  58%   |                                                                       |====================================                          |  59%   |                                                                       |=====================================                         |  59%   |                                                                       |=====================================                         |  60%   |                                                                       |======================================                        |  60%   |                                                                       |======================================                        |  61%   |                                                                       |======================================                        |  62%   |                                                                       |=======================================                       |  62%   |                                                                       |=======================================                       |  63%   |                                                                       |=======================================                       |  64%   |                                                                       |========================================                      |  64%   |                                                                       |========================================                      |  65%   |                                                                       |=========================================                     |  65%   |                                                                       |=========================================                     |  66%   |                                                                       |=========================================                     |  67%   |                                                                       |==========================================                    |  67%   |                                                                       |==========================================                    |  68%   |                                                                       |==========================================                    |  69%   |                                                                       |===========================================                   |  69%   |                                                                       |===========================================                   |  70%   |                                                                       |============================================                  |  70%   |                                                                       |============================================                  |  71%   |                                                                       |============================================                  |  72%   |                                                                       |=============================================                 |  72%   |                                                                       |=============================================                 |  73%   |                                                                       |==============================================                |  73%   |                                                                       |==============================================                |  74%   |                                                                       |==============================================                |  75%   |                                                                       |===============================================               |  75%   |                                                                       |===============================================               |  76%   |                                                                       |===============================================               |  77%   |                                                                       |================================================              |  77%   |                                                                       |================================================              |  78%   |                                                                       |=================================================             |  78%   |                                                                       |=================================================             |  79%   |                                                                       |=================================================             |  80%   |                                                                       |==================================================            |  80%   |                                                                       |==================================================            |  81%   |                                                                       |===================================================           |  81%   |                                                                       |===================================================           |  82%   |                                                                       |===================================================           |  83%   |                                                                       |====================================================          |  83%   |                                                                       |====================================================          |  84%   |                                                                       |====================================================          |  85%   |                                                                       |=====================================================         |  85%   |                                                                       |=====================================================         |  86%   |                                                                       |======================================================        |  86%   |                                                                       |======================================================        |  87%   |                                                                       |======================================================        |  88%   |                                                                       |=======================================================       |  88%   |                                                                       |=======================================================       |  89%   |                                                                       |=======================================================       |  90%   |                                                                       |========================================================      |  90%   |                                                                       |========================================================      |  91%   |                                                                       |=========================================================     |  91%   |                                                                       |=========================================================     |  92%   |                                                                       |=========================================================     |  93%   |                                                                       |==========================================================    |  93%   |                                                                       |==========================================================    |  94%   |                                                                       |===========================================================   |  94%   |                                                                       |===========================================================   |  95%   |                                                                       |===========================================================   |  96%   |                                                                       |============================================================  |  96%   |                                                                       |============================================================  |  97%   |                                                                       |============================================================  |  98%   |                                                                       |============================================================= |  98%   |                                                                       |============================================================= |  99%   |                                                                       |==============================================================|  99%   |                                                                       |==============================================================| 100% #> threshold of 0.9 has been provided. Samples will be added until quantile ratio is reached #> Underrepresented Quantile 1 - A total of 5 samples have been allocated. #> Underrepresented Quantile 2 - A total of 2 samples have been allocated. #> Underrepresented Quantile 3 - A total of 6 samples have been allocated. #> Underrepresented Quantile 4 - A total of 2 samples have been allocated. #> Underrepresented Quantile 5 - A total of 2 samples have been allocated. #> Underrepresented Quantile 6 - A total of 6 samples have been allocated. #> Underrepresented Quantile 7 - A total of 6 samples have been allocated. #> Underrepresented Quantile 8 - A total of 5 samples have been allocated. #> Underrepresented Quantile 9 - A total of 3 samples have been allocated. #> Underrepresented Quantile 10 - A total of 2 samples have been allocated. #> Underrepresented Quantile 11 - A total of 1 samples have been allocated. #> Underrepresented Quantile 12 - A total of 1 samples have been allocated. #> Underrepresented Quantile 13 - A total of 5 samples have been allocated. #> Underrepresented Quantile 14 - A total of 1 samples have been allocated. #> Underrepresented Quantile 15 - A total of 3 samples have been allocated. #> A total of 50 new samples added  #> Simple feature collection with 150 features and 4 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337710 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>        type     zmean pzabove2  zsd               geometry #> 1  existing 11.490000     79.7 4.96 POINT (434970 5343030) #> 2  existing 10.679999     91.9 3.90 POINT (435590 5340510) #> 3  existing  5.640000     24.8 4.23 POINT (434290 5338670) #> 4  existing  7.490000     38.5 3.61 POINT (435170 5340410) #> 5  existing  9.170000     69.4 4.20 POINT (437550 5340650) #> 6  existing 11.059999     79.8 5.30 POINT (435850 5340130) #> 7  existing  9.240000     74.8 5.34 POINT (431630 5343230) #> 8  existing  9.420000     89.6 3.63 POINT (436510 5340870) #> 9  existing  9.059999     65.1 4.80 POINT (435990 5339950) #> 10 existing  8.170000     93.5 3.38 POINT (438250 5337770)  sample_ahels(   mraster = mr[[1:3]],   existing = e,   nQuant = 20,   nSamp = 300,   filename = tempfile(fileext = \".shp\") ) #> Creating covariance matrix. #>    |                                                                       |                                                              |   0%   |                                                                       |                                                              |   1%   |                                                                       |=                                                             |   1%   |                                                                       |=                                                             |   2%   |                                                                       |==                                                            |   2%   |                                                                       |==                                                            |   3%   |                                                                       |==                                                            |   4%   |                                                                       |===                                                           |   4%   |                                                                       |===                                                           |   5%   |                                                                       |===                                                           |   6%   |                                                                       |====                                                          |   6%   |                                                                       |====                                                          |   7%   |                                                                       |=====                                                         |   7%   |                                                                       |=====                                                         |   8%   |                                                                       |=====                                                         |   9%   |                                                                       |======                                                        |   9%   |                                                                       |======                                                        |  10%   |                                                                       |=======                                                       |  10%   |                                                                       |=======                                                       |  11%   |                                                                       |=======                                                       |  12%   |                                                                       |========                                                      |  12%   |                                                                       |========                                                      |  13%   |                                                                       |========                                                      |  14%   |                                                                       |=========                                                     |  14%   |                                                                       |=========                                                     |  15%   |                                                                       |==========                                                    |  15%   |                                                                       |==========                                                    |  16%   |                                                                       |==========                                                    |  17%   |                                                                       |===========                                                   |  17%   |                                                                       |===========                                                   |  18%   |                                                                       |===========                                                   |  19%   |                                                                       |============                                                  |  19%   |                                                                       |============                                                  |  20%   |                                                                       |=============                                                 |  20%   |                                                                       |=============                                                 |  21%   |                                                                       |=============                                                 |  22%   |                                                                       |==============                                                |  22%   |                                                                       |==============                                                |  23%   |                                                                       |===============                                               |  23%   |                                                                       |===============                                               |  24%   |                                                                       |===============                                               |  25%   |                                                                       |================                                              |  25%   |                                                                       |================                                              |  26%   |                                                                       |================                                              |  27%   |                                                                       |=================                                             |  27%   |                                                                       |=================                                             |  28%   |                                                                       |==================                                            |  28%   |                                                                       |==================                                            |  29%   |                                                                       |==================                                            |  30%   |                                                                       |===================                                           |  30%   |                                                                       |===================                                           |  31%   |                                                                       |====================                                          |  31%   |                                                                       |====================                                          |  32%   |                                                                       |====================                                          |  33%   |                                                                       |=====================                                         |  33%   |                                                                       |=====================                                         |  34%   |                                                                       |=====================                                         |  35%   |                                                                       |======================                                        |  35%   |                                                                       |======================                                        |  36%   |                                                                       |=======================                                       |  36%   |                                                                       |=======================                                       |  37%   |                                                                       |=======================                                       |  38%   |                                                                       |========================                                      |  38%   |                                                                       |========================                                      |  39%   |                                                                       |========================                                      |  40%   |                                                                       |=========================                                     |  40%   |                                                                       |=========================                                     |  41%   |                                                                       |==========================                                    |  41%   |                                                                       |==========================                                    |  42%   |                                                                       |==========================                                    |  43%   |                                                                       |===========================                                   |  43%   |                                                                       |===========================                                   |  44%   |                                                                       |============================                                  |  44%   |                                                                       |============================                                  |  45%   |                                                                       |============================                                  |  46%   |                                                                       |=============================                                 |  46%   |                                                                       |=============================                                 |  47%   |                                                                       |=============================                                 |  48%   |                                                                       |==============================                                |  48%   |                                                                       |==============================                                |  49%   |                                                                       |===============================                               |  49%   |                                                                       |===============================                               |  50%   |                                                                       |===============================                               |  51%   |                                                                       |================================                              |  51%   |                                                                       |================================                              |  52%   |                                                                       |=================================                             |  52%   |                                                                       |=================================                             |  53%   |                                                                       |=================================                             |  54%   |                                                                       |==================================                            |  54%   |                                                                       |==================================                            |  55%   |                                                                       |==================================                            |  56%   |                                                                       |===================================                           |  56%   |                                                                       |===================================                           |  57%   |                                                                       |====================================                          |  57%   |                                                                       |====================================                          |  58%   |                                                                       |====================================                          |  59%   |                                                                       |=====================================                         |  59%   |                                                                       |=====================================                         |  60%   |                                                                       |======================================                        |  60%   |                                                                       |======================================                        |  61%   |                                                                       |======================================                        |  62%   |                                                                       |=======================================                       |  62%   |                                                                       |=======================================                       |  63%   |                                                                       |=======================================                       |  64%   |                                                                       |========================================                      |  64%   |                                                                       |========================================                      |  65%   |                                                                       |=========================================                     |  65%   |                                                                       |=========================================                     |  66%   |                                                                       |=========================================                     |  67%   |                                                                       |==========================================                    |  67%   |                                                                       |==========================================                    |  68%   |                                                                       |==========================================                    |  69%   |                                                                       |===========================================                   |  69%   |                                                                       |===========================================                   |  70%   |                                                                       |============================================                  |  70%   |                                                                       |============================================                  |  71%   |                                                                       |============================================                  |  72%   |                                                                       |=============================================                 |  72%   |                                                                       |=============================================                 |  73%   |                                                                       |==============================================                |  73%   |                                                                       |==============================================                |  74%   |                                                                       |==============================================                |  75%   |                                                                       |===============================================               |  75%   |                                                                       |===============================================               |  76%   |                                                                       |===============================================               |  77%   |                                                                       |================================================              |  77%   |                                                                       |================================================              |  78%   |                                                                       |=================================================             |  78%   |                                                                       |=================================================             |  79%   |                                                                       |=================================================             |  80%   |                                                                       |==================================================            |  80%   |                                                                       |==================================================            |  81%   |                                                                       |===================================================           |  81%   |                                                                       |===================================================           |  82%   |                                                                       |===================================================           |  83%   |                                                                       |====================================================          |  83%   |                                                                       |====================================================          |  84%   |                                                                       |====================================================          |  85%   |                                                                       |=====================================================         |  85%   |                                                                       |=====================================================         |  86%   |                                                                       |======================================================        |  86%   |                                                                       |======================================================        |  87%   |                                                                       |======================================================        |  88%   |                                                                       |=======================================================       |  88%   |                                                                       |=======================================================       |  89%   |                                                                       |=======================================================       |  90%   |                                                                       |========================================================      |  90%   |                                                                       |========================================================      |  91%   |                                                                       |=========================================================     |  91%   |                                                                       |=========================================================     |  92%   |                                                                       |=========================================================     |  93%   |                                                                       |==========================================================    |  93%   |                                                                       |==========================================================    |  94%   |                                                                       |===========================================================   |  94%   |                                                                       |===========================================================   |  95%   |                                                                       |===========================================================   |  96%   |                                                                       |============================================================  |  96%   |                                                                       |============================================================  |  97%   |                                                                       |============================================================  |  98%   |                                                                       |============================================================= |  98%   |                                                                       |============================================================= |  99%   |                                                                       |==============================================================|  99%   |                                                                       |==============================================================| 100% #> nSamp of 300 has been provided. Samples will be added until this number is reached #> Underrepresented Quantile 1 - A total of 3 samples have been allocated. #> Underrepresented Quantile 2 - A total of 3 samples have been allocated. #> Underrepresented Quantile 3 - A total of 2 samples have been allocated. #> Underrepresented Quantile 4 - A total of 4 samples have been allocated. #> Underrepresented Quantile 5 - A total of 2 samples have been allocated. #> Underrepresented Quantile 6 - A total of 2 samples have been allocated. #> Underrepresented Quantile 7 - A total of 7 samples have been allocated. #> Underrepresented Quantile 8 - A total of 2 samples have been allocated. #> Underrepresented Quantile 9 - A total of 3 samples have been allocated. #> Underrepresented Quantile 10 - A total of 7 samples have been allocated. #> Underrepresented Quantile 11 - A total of 5 samples have been allocated. #> Underrepresented Quantile 12 - A total of 2 samples have been allocated. #> Underrepresented Quantile 13 - A total of 1 samples have been allocated. #> Underrepresented Quantile 14 - A total of 4 samples have been allocated. #> Underrepresented Quantile 15 - A total of 4 samples have been allocated. #> Underrepresented Quantile 16 - A total of 3 samples have been allocated. #> Underrepresented Quantile 17 - A total of 4 samples have been allocated. #> Underrepresented Quantile 18 - A total of 8 samples have been allocated. #> Underrepresented Quantile 19 - A total of 1 samples have been allocated. #> Underrepresented Quantile 20 - A total of 1 samples have been allocated. #> Underrepresented Quantile 21 - A total of 4 samples have been allocated. #> Underrepresented Quantile 22 - A total of 2 samples have been allocated. #> Underrepresented Quantile 23 - A total of 2 samples have been allocated. #> Underrepresented Quantile 24 - A total of 1 samples have been allocated. #> Underrepresented Quantile 25 - A total of 7 samples have been allocated. #> Underrepresented Quantile 26 - A total of 2 samples have been allocated. #> Underrepresented Quantile 27 - A total of 5 samples have been allocated. #> Underrepresented Quantile 28 - A total of 1 samples have been allocated. #> Underrepresented Quantile 29 - A total of 4 samples have been allocated. #> Underrepresented Quantile 30 - A total of 4 samples have been allocated. #> Underrepresented Quantile 31 - A total of 5 samples have been allocated. #> Underrepresented Quantile 32 - A total of 4 samples have been allocated. #> Underrepresented Quantile 33 - A total of 1 samples have been allocated. #> Underrepresented Quantile 34 - A total of 3 samples have been allocated. #> Underrepresented Quantile 35 - A total of 4 samples have been allocated. #> Underrepresented Quantile 36 - A total of 5 samples have been allocated. #> Underrepresented Quantile 37 - A total of 2 samples have been allocated. #> Underrepresented Quantile 38 - A total of 1 samples have been allocated. #> Underrepresented Quantile 39 - A total of 2 samples have been allocated. #> Underrepresented Quantile 40 - A total of 1 samples have been allocated. #> Underrepresented Quantile 41 - A total of 6 samples have been allocated. #> Underrepresented Quantile 42 - A total of 1 samples have been allocated. #> Underrepresented Quantile 43 - A total of 1 samples have been allocated. #> Underrepresented Quantile 44 - A total of 3 samples have been allocated. #> Underrepresented Quantile 45 - A total of 2 samples have been allocated. #> Underrepresented Quantile 46 - A total of 4 samples have been allocated. #> Underrepresented Quantile 47 - A total of 6 samples have been allocated. #> Underrepresented Quantile 48 - A total of 3 samples have been allocated. #> Underrepresented Quantile 49 - A total of 1 samples have been allocated. #> Underrepresented Quantile 50 - A total of 1 samples have been allocated. #> Underrepresented Quantile 51 - A total of 3 samples have been allocated. #> Underrepresented Quantile 52 - A total of 2 samples have been allocated. #> Underrepresented Quantile 53 - A total of 4 samples have been allocated. #> Underrepresented Quantile 54 - A total of 1 samples have been allocated. #> Underrepresented Quantile 55 - A total of 1 samples have been allocated. #> Underrepresented Quantile 56 - A total of 4 samples have been allocated. #> Underrepresented Quantile 57 - A total of 2 samples have been allocated. #> Underrepresented Quantile 58 - A total of 1 samples have been allocated. #> Underrepresented Quantile 59 - A total of 1 samples have been allocated. #> Underrepresented Quantile 60 - A total of 2 samples have been allocated. #> Underrepresented Quantile 61 - A total of 3 samples have been allocated. #> Underrepresented Quantile 62 - A total of 3 samples have been allocated. #> Underrepresented Quantile 63 - A total of 3 samples have been allocated. #> Underrepresented Quantile 64 - A total of 3 samples have been allocated. #> Underrepresented Quantile 65 - A total of 3 samples have been allocated. #> Underrepresented Quantile 66 - A total of 1 samples have been allocated. #> Underrepresented Quantile 67 - A total of 1 samples have been allocated. #> Underrepresented Quantile 68 - A total of 3 samples have been allocated. #> Underrepresented Quantile 69 - A total of 3 samples have been allocated. #> Underrepresented Quantile 70 - A total of 2 samples have been allocated. #> Underrepresented Quantile 71 - A total of 1 samples have been allocated. #> Underrepresented Quantile 72 - A total of 6 samples have been allocated. #> Underrepresented Quantile 73 - A total of 4 samples have been allocated. #> Underrepresented Quantile 74 - A total of 3 samples have been allocated. #> Underrepresented Quantile 75 - A total of 7 samples have been allocated. #> Underrepresented Quantile 76 - A total of 3 samples have been allocated. #> Underrepresented Quantile 77 - A total of 3 samples have been allocated. #> Underrepresented Quantile 78 - A total of 4 samples have been allocated. #> Underrepresented Quantile 79 - A total of 2 samples have been allocated. #> Underrepresented Quantile 80 - A total of 1 samples have been allocated. #> Underrepresented Quantile 81 - A total of 1 samples have been allocated. #> Underrepresented Quantile 82 - A total of 1 samples have been allocated. #> Underrepresented Quantile 83 - A total of 2 samples have been allocated. #> Underrepresented Quantile 84 - A total of 2 samples have been allocated. #> Underrepresented Quantile 85 - A total of 1 samples have been allocated. #> Underrepresented Quantile 86 - A total of 3 samples have been allocated. #> Underrepresented Quantile 87 - A total of 1 samples have been allocated. #> Underrepresented Quantile 88 - A total of 6 samples have been allocated. #> Underrepresented Quantile 89 - A total of 1 samples have been allocated. #> Underrepresented Quantile 90 - A total of 5 samples have been allocated. #> Underrepresented Quantile 91 - A total of 4 samples have been allocated. #> Underrepresented Quantile 92 - A total of 1 samples have been allocated. #> Underrepresented Quantile 93 - A total of 2 samples have been allocated. #> Underrepresented Quantile 94 - A total of 3 samples have been allocated. #> Underrepresented Quantile 95 - A total of 3 samples have been allocated. #> Underrepresented Quantile 96 - A total of 1 samples have been allocated. #> Underrepresented Quantile 97 - A total of 1 samples have been allocated. #> Underrepresented Quantile 98 - A total of 2 samples have been allocated. #> Underrepresented Quantile 99 - A total of 3 samples have been allocated. #> Underrepresented Quantile 100 - A total of 3 samples have been allocated. #> Underrepresented Quantile 101 - A total of 6 samples have been allocated. #> Underrepresented Quantile 102 - A total of 3 samples have been allocated. #> Underrepresented Quantile 103 - A total of 3 samples have been allocated. #> Underrepresented Quantile 104 - A total of 1 samples have been allocated. #> Underrepresented Quantile 105 - A total of 1 samples have been allocated. #> Underrepresented Quantile 106 - A total of 1 samples have been allocated. #> Underrepresented Quantile 107 - A total of 3 samples have been allocated. #> A total of 300 new samples added #> Writing layer `file55ec58b428e9' to data source  #>   `C:\\Users\\tgood.stu\\AppData\\Local\\Temp\\RtmpMPmhqB\\file55ec58b428e9.shp' using driver `ESRI Shapefile' #> Writing 400 features with 4 fields and geometry type Point. #> Simple feature collection with 400 features and 4 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337730 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>        type     zmean pzabove2  zsd               geometry #> 1  existing 11.490000     79.7 4.96 POINT (434970 5343030) #> 2  existing 10.679999     91.9 3.90 POINT (435590 5340510) #> 3  existing  5.640000     24.8 4.23 POINT (434290 5338670) #> 4  existing  7.490000     38.5 3.61 POINT (435170 5340410) #> 5  existing  9.170000     69.4 4.20 POINT (437550 5340650) #> 6  existing 11.059999     79.8 5.30 POINT (435850 5340130) #> 7  existing  9.240000     74.8 5.34 POINT (431630 5343230) #> 8  existing  9.420000     89.6 3.63 POINT (436510 5340870) #> 9  existing  9.059999     65.1 4.80 POINT (435990 5339950) #> 10 existing  8.170000     93.5 3.38 POINT (438250 5337770)"},{"path":"/reference/sample_balanced.html","id":null,"dir":"Reference","previous_headings":"","what":"Balanced sampling — sample_balanced","title":"Balanced sampling — sample_balanced","text":"Balanced raster sampling using lcube lpm2_kdtree methods","code":""},{"path":"/reference/sample_balanced.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Balanced sampling — sample_balanced","text":"","code":"sample_balanced(   mraster,   nSamp,   algorithm = \"lpm2_kdtree\",   p = NULL,   access = NULL,   buff_inner = NULL,   buff_outer = NULL,   plot = FALSE,   filename = NULL,   overwrite = FALSE )"},{"path":"/reference/sample_balanced.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Balanced sampling — sample_balanced","text":"mraster spatRaster. ALS metrics raster. nSamp Numeric. Number desired samples. algorithm Character. One lpm2_kdtree, lcube, lcubestratified p Numeric. Vector length equal number cells mraster representing inclusion probability candidate sample. Default = nSamp / N, N number cells. access sf. Road access network - must lines. buff_inner Numeric. Inner buffer boundary specifying distance access plots sampled. buff_outer Numeric. Outer buffer boundary specifying distance access plots can sampled. plot Logical. Plots output strata raster visualized strata boundary dividers. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc.","code":""},{"path":"/reference/sample_balanced.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Balanced sampling — sample_balanced","text":"sf object nSamp randomly sampled points.","code":""},{"path":"/reference/sample_balanced.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Balanced sampling — sample_balanced","text":"Anton Grafstrom Jonathan Lisic (2019). BalancedSampling: Balanced Spatially Balanced Sampling. R package version 1.5.5. https://CRAN.R-project.org/package=BalancedSampling Jonathan Lisic Anton Grafstrom (2018). SamplingBigData: Sampling Methods Big Data. R package version 1.0.0. https://CRAN.R-project.org/package=SamplingBigData Grafström, . Lisic, J (2018). BalancedSampling: Balanced Spatially Balanced Sampling.  R package version 1.5.4. http://www.antongrafstrom.se/balancedsampling","code":""},{"path":[]},{"path":"/reference/sample_balanced.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Balanced sampling — sample_balanced","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/sample_balanced.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Balanced sampling — sample_balanced","text":"","code":"if (FALSE) { #--- Load raster and existing plots---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  a <- system.file(\"extdata\", \"roads.shp\", package = \"sgsR\") ac <- sf::st_read(a)  sample_balanced(   mraster = mr,   nSamp = 200,   plot = TRUE )  sample_balanced(   mraster = mr,   nSamp = 100,   algorithm = \"lcube\",   access = ac,   buff_inner = 50,   buff_outer = 200 ) }"},{"path":"/reference/sample_clhs.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditioned Latin Hypercube Sampling — sample_clhs","title":"Conditioned Latin Hypercube Sampling — sample_clhs","text":"Conditioned Latin Hypercube Sampling using clhs functionality.","code":""},{"path":"/reference/sample_clhs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditioned Latin Hypercube Sampling — sample_clhs","text":"","code":"sample_clhs(   mraster,   nSamp,   iter = 10000,   cost = NULL,   existing = NULL,   access = NULL,   buff_inner = NULL,   buff_outer = NULL,   plot = FALSE,   details = FALSE,   filename = NULL,   overwrite = FALSE,   ... )"},{"path":"/reference/sample_clhs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditioned Latin Hypercube Sampling — sample_clhs","text":"mraster spatRaster. ALS metrics raster. nSamp Numeric. Number desired samples. iter Numeric. Value giving number iterations within Metropolis-Hastings process. cost Numeric/Character. Index name covariate within mraster used constrain cLHS sampling. default - NULL cost constraint used. existing sf. Samples resulting sample_* functions. access sf. Road access network - must lines. buff_inner Numeric. Inner buffer boundary specifying distance access plots sampled. buff_outer Numeric. Outer buffer boundary specifying distance access plots can sampled. plot Logical. Plots output strata raster samples. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. filename Character. Path write output samples. overwrite Logical. Choice overwrite existing filename exists. ... Additional arguments clhs sampling. See clhs.","code":""},{"path":"/reference/sample_clhs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditioned Latin Hypercube Sampling — sample_clhs","text":"sf object nSamp stratified samples.","code":""},{"path":"/reference/sample_clhs.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Conditioned Latin Hypercube Sampling — sample_clhs","text":"Minasny, B. McBratney, .B. 2006. conditioned Latin hypercube method sampling presence ancillary information. Computers Geosciences, 32:1378-1388. Minasny, B. . B. McBratney, .B.. 2010. Conditioned Latin Hypercube Sampling Calibrating Soil Sensor Data Soil Properties. : Proximal Soil Sensing, Progress Soil Science, pages 111-119. Roudier, P., Beaudette, D.E. Hewitt, .E. 2012. conditioned Latin hypercube sampling algorithm incorporating operational constraints. : Digital Soil Assessments Beyond. Proceedings 5th Global Workshop Digital Soil Mapping, Sydney, Australia.","code":""},{"path":[]},{"path":"/reference/sample_clhs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Conditioned Latin Hypercube Sampling — sample_clhs","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/sample_clhs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditioned Latin Hypercube Sampling — sample_clhs","text":"","code":"#--- Load raster and existing plots---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  e <- system.file(\"extdata\", \"existing.shp\", package = \"sgsR\") e <- sf::st_read(e) #> Reading layer `existing' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\existing.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 100 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           unknown  a <- system.file(\"extdata\", \"roads.shp\", package = \"sgsR\") ac <- sf::st_read(a) #> Reading layer `roads' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\roads.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 167 features and 2 fields #> Geometry type: MULTILINESTRING #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337700 xmax: 438560 ymax: 5343240 #> Projected CRS: UTM_Zone_17_Northern_Hemisphere  sample_clhs(   mraster = mr,   nSamp = 200,   plot = TRUE,   iter = 100 )  #> Simple feature collection with 200 features and 8 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438530 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>       zmean pzabove2  zsd  zq20  zq50  zq70  zq90 type #> 45649  6.42     95.8 2.99  3.96  6.15  7.48 11.74  new #> 67712 12.37     90.2 3.17 10.08 12.96 14.20 16.49  new #> 56048  7.05     73.0 3.47  3.27  7.21  9.26 12.41  new #> 75891  5.10     80.7 2.62  2.68  4.65  6.32  9.84  new #> 3702  13.89     85.5 5.92  6.85 16.36 18.18 20.22  new #> 60833  6.05     74.2 3.74  2.22  5.90  8.73 12.25  new #> 71938  5.68     65.9 2.86  2.72  5.53  7.36 10.43  new #> 65110  5.96     88.0 2.95  3.31  5.77  7.14 11.01  new #> 35353 14.04     95.8 3.11 11.84 14.70 15.92 17.99  new #> 77995 12.60     84.9 6.34  6.93 11.24 16.02 23.49  new #>                     geometry #> 45649 POINT (434970 5340570) #> 67712 POINT (436250 5339230) #> 56048 POINT (432050 5339950) #> 75891 POINT (438030 5338590) #> 3702  POINT (431670 5342990) #> 60833 POINT (431610 5339650) #> 71938 POINT (435630 5338910) #> 65110 POINT (437630 5339410) #> 35353 POINT (437210 5341190) #> 77995 POINT (435390 5338450)  sample_clhs(   mraster = mr,   nSamp = 400,   existing = e,   iter = 250,   details = TRUE ) #> $clhs #>   [1] 32659  1547   956 14357 11889 25912  7328 90247  7069 47929 72177 #>  [12] 27156 62333 54053 43269 60817 55329 54336 77781 74963   977 38814 #>  [23]   248 28156 25020 28430 37138 76716 15139 10709 80645 60186  8678 #>  [34] 17625 29552 66564 30918 69004 51115 25219 29250 17850 82236 86872 #>  [45] 17942 63700 70939 20550 17400 88656 50703 14744   338 24281 23468 #>  [56] 65080 77390 32251 12683 44148 65557 49553 75538 19832  5516 31088 #>  [67] 29682  7348 51759 55720 85221 88546 15633 76381 51538 57388  5251 #>  [78] 20988 89336 45593 86332 81877  4254   861 75020 91201 34661 87643 #>  [89] 34221 34794 42631 49493 38509 15387  1651 71867 59285 63808 75664 #> [100] 69087 64897 80986  3532  2347 54553 19919 89770 22799 37853 13785 #> [111] 80796 67691 45847 41167 36846 49862  2929 22082 79217 42134  3042 #> [122] 29040 84763 40260 55899 31724 63129 68470 82991  3039 64107 19559 #> [133] 53885 84348 49170 18672 43136 31869 61247 24733 48641 61113 60349 #> [144] 21768 13903 83791 81100 54456 30547 59422  5114  2590 55274 88683 #> [155] 74618   726 69041 44570 80906 11383 82384 83958 63383 50909 26641 #> [166] 46005 55475 51544  2596  9970 58095 86633 89402 38396 61139 40004 #> [177] 84074  5872 68294   552 44252 16743 71240 80216 52046  8792 78767 #> [188] 44221 82240 46674 61565 23823 24251 75698 26371 84848 78339 81651 #> [199] 65249 40834 75812 83637 25230 69996 51824 26629 73550 10831 49868 #> [210] 48496 47096 72853 51599 69957 82607 12185 12560 36876 61297 15372 #> [221] 57393 76545 70843 82188 47076 57523 86024 35383 63025 88069 18203 #> [232] 18540 74001 62344  4723 14860 87977 79406 33353 17194 14404 23250 #> [243] 26628  9660 64931 58864 51780 13215 75236 63284 53446 17318 42787 #> [254] 40769 66855  4258 73314 29032 78103 78540 47837 42601 46934 62847 #> [265] 22402 39042 26074 73133   135 11510 88229 39448 38121 66425 25965 #> [276] 78222 68766 18099  8884 71954 66055 14140   754 54224 59675 41296 #> [287] 64308 34997 76515 76210 54582 50115 14052 36371 36002 18254 42179 #> [298] 35878 19439 26910 52899 60468 12951 19391 86335 78297   830 10245 #> [309] 50441 88174   188 90423 82578 56641 76678 39916 68166  1996 73519 #> [320] 65350  6229 85388 64390 44008 69776 22820 89264 66779 52457 54893 #> [331] 78975 60097 27707 50374 75107 84572 58685 41971  2514 24946 57451 #> [342] 80647 66211 76836 30179 35753 47406 80478 32753 12988 80502 79650 #> [353] 74016 18531 59692 48662 31985 61865 56259 30997  9956 72712  9455 #> [364] 10478 10067 38732 40027 27227 41741 77212 11196 43828 65580 80573 #> [375] 63978 67215 62178 90616 90935 77889 43415 57926 76894 55910 51163 #> [386] 49359 32828 76145 25844 71479 44276 31249 11868 61959 74422  3850 #> [397] 20933 24002 46906 61503 #>  #> $samples #> Simple feature collection with 400 features and 8 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337710 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>       zmean  pzabove2  zsd  zq20  zq50  zq70  zq90 type #> 32559 11.40 78.400002 3.87  8.08 12.33 13.93 16.18  new #> 1447  11.55 78.400002 5.42  5.65 12.83 15.29 18.89  new #> 856   13.29 93.599998 3.34 11.94 13.68 14.82 17.42  new #> 14257  0.00  0.000000 0.00  0.00  0.00  0.00  0.00  new #> 11789 11.09 93.900002 2.73  9.00 11.06 12.24 15.94  new #> 25812  3.23 54.600002 2.20  1.81  2.33  3.23  8.72  new #> 7228   2.65  8.900001 1.36  1.51  2.07  3.15  5.41  new #> 90147 12.10 83.599998 3.88  9.01 12.84 14.58 17.16  new #> 6969   6.19 67.599998 2.91  3.74  5.90  7.33 11.27  new #> 47829  4.05 46.100002 2.46  1.79  3.40  5.14  8.59  new #>                     geometry #> 32559 POINT (436370 5341350) #> 1447  POINT (435010 5343150) #> 856   POINT (435370 5343190) #> 14257 POINT (437030 5342390) #> 11789 POINT (433550 5342530) #> 25812 POINT (432870 5341730) #> 7228  POINT (437930 5342810) #> 90147 POINT (431930 5337750) #> 6969  POINT (432610 5342810) #> 47829 POINT (432030 5340430) #>   sample_clhs(   mraster = mr,   nSamp = 200,   iter = 200,   existing = e,   access = ac,   buff_inner = 100,   buff_outer = 300,   plot = TRUE ) #> An access layer has been provided. An internal buffer of 100 m and an external buffer of 300 m have been applied  #> Simple feature collection with 200 features and 8 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431270 ymin: 5337750 xmax: 438510 ymax: 5343150 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>       zmean pzabove2  zsd  zq20  zq50  zq70  zq90 type #> 9585  10.25     80.3 3.92  6.86 10.57 12.37 16.40  new #> 7273   2.74     33.8 1.11  1.78  2.48  3.14  4.85  new #> 11609  3.45     16.1 3.10  1.50  1.91  2.90 10.37  new #> 27128 15.09     95.6 3.48 12.84 15.11 16.87 20.26  new #> 38383  4.73     64.5 1.64  3.37  4.77  5.48  7.24  new #> 36692 11.17     86.6 5.50  5.22 11.91 14.68 19.22  new #> 9293   7.16     82.5 3.21  4.10  7.27  9.24 11.73  new #> 33204 10.31     93.2 3.48  7.88 10.97 12.21 15.04  new #> 22401 15.64     86.4 7.94  6.54 18.15 21.67 25.66  new #> 6257   6.81     65.9 2.68  4.44  6.83  8.29 11.32  new #>                     geometry #> 9585  POINT (433010 5341970) #> 7273  POINT (435410 5342290) #> 11609 POINT (434890 5341770) #> 27128 POINT (433130 5339530) #> 38383 POINT (437050 5337810) #> 36692 POINT (431750 5338070) #> 9293  POINT (435830 5342010) #> 33204 POINT (431510 5338550) #> 22401 POINT (433010 5340310) #> 6257  POINT (433430 5342390)  #--- cost constrained examples ---# #--- calculate distance to access layer for each pixel in mr ---# mr.c <- calculate_distance(   raster = mr,   access = ac ) #> calculating per pixel distance to provided access layer  sample_clhs(   mraster = mr.c,   nSamp = 250,   iter = 200,   cost = \"dist2access\",   plot = TRUE )  #> Simple feature collection with 250 features and 9 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337730 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>           zmean pzabove2  zsd      zq20  zq50  zq70  zq90 dist2access #> 52009 13.719999     95.1 3.13 12.309999 14.03 15.12 17.67   297.19449 #> 65787  9.309999     88.3 4.56  5.460000  8.63 11.19 17.65   225.78857 #> 77075  4.830000     69.7 2.89  2.530000  4.20  5.45 11.53   234.78335 #> 25130  7.120000     71.6 3.33  3.840000  7.10  8.87 12.88   147.12390 #> 74543  5.960000     65.6 3.02  3.130000  5.84  7.32 11.27   229.60290 #> 20345  2.410000     28.6 0.94  1.640000  2.21  2.65  4.31    79.14529 #> 43460 12.040000     86.7 4.60  8.599999 12.92 14.72 18.04   194.03574 #> 42673 12.490000     87.0 4.72  8.770000 13.17 15.39 18.94   855.63091 #> 7847   2.320000      8.3 1.18  1.510000  1.92  2.36  4.52   201.11720 #> 22801  2.820000     34.4 1.39  1.730000  2.44  3.05  5.76   104.22014 #>       type               geometry #> 52009  new POINT (433570 5340190) #> 65787  new POINT (432710 5339350) #> 77075  new POINT (436870 5338510) #> 25130  new POINT (432590 5341770) #> 74543  new POINT (434950 5338690) #> 20345  new POINT (435430 5342050) #> 43460  new POINT (431830 5340690) #> 42673  new POINT (437350 5340750) #> 7847   new POINT (435730 5342770) #> 22801  new POINT (434430 5341910)  sample_clhs(   mraster = mr.c,   nSamp = 250,   existing = e,   iter = 200,   cost = \"dist2access\",   plot = TRUE )  #> Simple feature collection with 250 features and 9 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431130 ymin: 5337730 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>       zmean pzabove2  zsd  zq20  zq50      zq70  zq90 dist2access type #> 42285 11.09     88.8 3.52  8.63 11.67 13.009999 15.90    14.71871  new #> 35725  5.13     89.5 1.68  3.64  5.09  6.030000  7.97   333.68441  new #> 24245 10.04     92.9 3.69  6.96 10.08 11.750000 16.60   283.77112  new #> 10898  7.21     86.5 2.12  5.42  7.46  8.429999 10.30    56.28943  new #> 68703 12.37     89.6 3.86 10.50 13.52 14.599999 16.31   656.11045  new #> 14177  4.11     17.2 3.07  1.59  2.63  5.350000 10.99   199.85255  new #> 49494 12.96     96.7 3.80 10.30 12.87 14.549999 19.49   245.71663  new #> 18096  4.85     50.3 2.84  2.28  4.10  5.920000 10.49   241.84615  new #> 33543 16.04     92.7 4.51 14.56 17.51 18.529999 20.08   710.63961  new #> 12767 12.65     91.3 3.10 10.77 13.24 14.299999 16.55   225.73657  new #>                     geometry #> 42285 POINT (436310 5340770) #> 35725 POINT (437790 5341170) #> 24245 POINT (435390 5341830) #> 10898 POINT (434450 5342590) #> 68703 POINT (431250 5339150) #> 14177 POINT (435310 5342390) #> 49494 POINT (431270 5340330) #> 18096 POINT (434310 5342170) #> 33543 POINT (435410 5341290) #> 12767 POINT (434050 5342470)"},{"path":"/reference/sample_srs.html","id":null,"dir":"Reference","previous_headings":"","what":"Simple random sampling — sample_srs","title":"Simple random sampling — sample_srs","text":"Randomly sample within stratification raster extent.","code":""},{"path":"/reference/sample_srs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simple random sampling — sample_srs","text":"","code":"sample_srs(   raster,   nSamp,   mindist = NULL,   access = NULL,   buff_inner = NULL,   buff_outer = NULL,   plot = FALSE,   filename = NULL,   overwrite = FALSE )"},{"path":"/reference/sample_srs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simple random sampling — sample_srs","text":"raster spatRaster. Raster used random sampling. nSamp Numeric. Number desired samples. mindist Numeric. Minimum allowable distance selected samples. Default = NULL. access sf. Road access network - must lines. buff_inner Numeric. Inner buffer boundary specifying distance access plots sampled. buff_outer Numeric. Outer buffer boundary specifying distance access plots can sampled. plot Logical. Plots output strata raster samples. filename Character. Path write output samples. overwrite Logical. Choice overwrite existing filename exists.","code":""},{"path":"/reference/sample_srs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simple random sampling — sample_srs","text":"sf object nSamp randomly sampled points.","code":""},{"path":[]},{"path":"/reference/sample_srs.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Simple random sampling — sample_srs","text":"Tristan R.H. Goodbody & Martin Queinnec","code":""},{"path":"/reference/sample_srs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simple random sampling — sample_srs","text":"","code":"#--- Load raster and access files ---# r <- system.file(\"extdata\", \"kmeans.tif\", package = \"sgsR\") sr <- terra::rast(r)  a <- system.file(\"extdata\", \"roads.shp\", package = \"sgsR\") ac <- sf::st_read(a) #> Reading layer `roads' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\roads.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 167 features and 2 fields #> Geometry type: MULTILINESTRING #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337700 xmax: 438560 ymax: 5343240 #> Projected CRS: UTM_Zone_17_Northern_Hemisphere  #--- perform simple random sampling ---# sample_srs(   raster = sr,   nSamp = 200,   plot = TRUE )  #> Simple feature collection with 200 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431130 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (436230 5341890) #> 2  POINT (436230 5341890) #> 3  POINT (431230 5340910) #> 4  POINT (438010 5341550) #> 5  POINT (431430 5341330) #> 6  POINT (435930 5337830) #> 7  POINT (438410 5342830) #> 8  POINT (432550 5342330) #> 9  POINT (437130 5341150) #> 10 POINT (431930 5340550)  sample_srs(   raster = sr,   nSamp = 200,   access = ac,   mindist = 200,   buff_inner = 50,   buff_outer = 200 ) #> An access layer has been provided. An internal buffer of 50 m and an external buffer of 200 m have been applied #> Registered S3 method overwritten by 'spatstat.geom': #>   method     from #>   print.boxx cli  #> Simple feature collection with 200 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431210 ymin: 5337710 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (432510 5341030) #> 2  POINT (434270 5341830) #> 3  POINT (431970 5342590) #> 4  POINT (433690 5342750) #> 5  POINT (435170 5339290) #> 6  POINT (432270 5342070) #> 7  POINT (435850 5342950) #> 8  POINT (432170 5341290) #> 9  POINT (438010 5338690) #> 10 POINT (434870 5342910)  sample_srs(   raster = sr,   nSamp = 200,   access = ac,   buff_inner = 50,   buff_outer = 200,   filename = tempfile(fileext = \".shp\") ) #> An access layer has been provided. An internal buffer of 50 m and an external buffer of 200 m have been applied #> Writing layer `file55ec56affdc' to data source  #>   `C:\\Users\\tgood.stu\\AppData\\Local\\Temp\\RtmpMPmhqB\\file55ec56affdc.shp' using driver `ESRI Shapefile' #> Writing 200 features with 0 fields and geometry type Point. #> Simple feature collection with 200 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431170 ymin: 5337750 xmax: 438550 ymax: 5343210 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (433890 5343210) #> 2  POINT (433890 5343210) #> 3  POINT (437010 5337890) #> 4  POINT (437910 5342470) #> 5  POINT (434290 5338230) #> 6  POINT (432970 5339150) #> 7  POINT (438170 5339330) #> 8  POINT (434630 5342970) #> 9  POINT (436430 5340290) #> 10 POINT (438050 5340310)"},{"path":"/reference/sample_strat.html","id":null,"dir":"Reference","previous_headings":"","what":"Stratified sampling — sample_strat","title":"Stratified sampling — sample_strat","text":"Sampling based stratified raster.","code":""},{"path":"/reference/sample_strat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stratified sampling — sample_strat","text":"","code":"sample_strat(   sraster,   nSamp,   force = FALSE,   allocation = \"prop\",   mraster = NULL,   mindist = NULL,   existing = NULL,   include = FALSE,   access = NULL,   buff_inner = NULL,   buff_outer = NULL,   wrow = 3,   wcol = 3,   plot = FALSE,   details = FALSE,   filename = NULL,   overwrite = FALSE )"},{"path":"/reference/sample_strat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stratified sampling — sample_strat","text":"sraster spatRaster. Stratification raster used sampling. nSamp Numeric. Number desired samples. existing include force influence value. force Logical. Default = FALSE - force nSamp exactly user defined value cases nSamp sraster strata count equally divisible. effect existing provided. allocation Character. Allocation algorithm used. Either prop (default) proportional allocation optim optimal allocation (equal sampling cost) equal equal number samples (defined nSamp)  strata. mraster spatRaster. ALS metric raster. Required allocation = optim. mindist Numeric. Minimum allowable distance selected samples. Default = NULL. existing sf data.frame.  Existing plot network. include Logical. TRUE include existing plots nSamp total. access sf. Road access network - must lines. buff_inner Numeric. Inner buffer boundary specifying distance access plots sampled. buff_outer Numeric. Outer buffer boundary specifying distance access plots can sampled. wrow Numeric. Number row focal window (default 3). wcol Numeric. Number columns focal window (default 3). plot Logical. Plots existing (circles) new (crosses) samples. details Logical. FALSE (default) output sf object stratified samples. TRUE return list $details additional sampling information $raster sf object stratified samples. filename Character. Path write output samples. overwrite Logical. Choice overwrite existing filename exists.","code":""},{"path":"/reference/sample_strat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stratified sampling — sample_strat","text":"sf object nSamp stratified samples.","code":""},{"path":"/reference/sample_strat.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Stratified sampling — sample_strat","text":"sampling performed 2 stages: Rule 1 - Sample within grouped stratum pixels defined within wrow, wcol parameters Rule 2 - samples exist satisfy Rule 1  individual stratum pixels sampled. rule applied allocate sample defined rule attribute output samples.","code":""},{"path":"/reference/sample_strat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Stratified sampling — sample_strat","text":"Queinnec, M., White, J. C., & Coops, N. C. (2021).  Comparing airborne spaceborne photon-counting LiDAR canopy  structural estimates across different boreal forest types.  Remote Sensing Environment, 262 (August 2020), 112510.  https://doi.org/10.1016/j.rse.2021.112510","code":""},{"path":[]},{"path":"/reference/sample_strat.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Stratified sampling — sample_strat","text":"Tristan R.H. Goodbody & Martin Queinnec","code":""},{"path":"/reference/sample_strat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stratified sampling — sample_strat","text":"","code":"#--- Load raster and access files ---# r <- system.file(\"extdata\", \"kmeans.tif\", package = \"sgsR\") sr <- terra::rast(r)  a <- system.file(\"extdata\", \"roads.shp\", package = \"sgsR\") ac <- sf::st_read(a) #> Reading layer `roads' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\roads.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 167 features and 2 fields #> Geometry type: MULTILINESTRING #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337700 xmax: 438560 ymax: 5343240 #> Projected CRS: UTM_Zone_17_Northern_Hemisphere  e <- system.file(\"extdata\", \"existing.shp\", package = \"sgsR\") e <- sf::st_read(e) #> Reading layer `existing' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\existing.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 100 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           unknown  #--- perform stratified sampling random sampling ---# sample_strat(   sraster = sr,   nSamp = 200,   plot = TRUE ) #> Implementing porportional allocation of samples #> nSamp of 200 is not perfectly divisible based on strata distribution. nSamp of 199 will be returned. Use \"force = TRUE\" to brute force to 200. #> Processing strata : 1 #> Processing strata : 2 #> Processing strata : 3 #> Processing strata : 4 #> Processing strata : 5 #> Processing strata : 6 #> Processing strata : 7 #> Processing strata : 8 #> Processing strata : 9 #> Processing strata : 10  #> Simple feature collection with 199 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431210 ymin: 5337750 xmax: 438510 ymax: 5343170 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>    strata type  rule               geometry #> x       1  new rule1 POINT (432750 5338430) #> x1      1  new rule1 POINT (433290 5338050) #> x2      1  new rule1 POINT (433290 5338070) #> x3      1  new rule1 POINT (432730 5338350) #> x4      1  new rule1 POINT (438390 5340830) #> x5      1  new rule1 POINT (435490 5340170) #> x6      1  new rule1 POINT (433190 5338750) #> x7      1  new rule1 POINT (437350 5340110) #> x8      1  new rule1 POINT (437050 5340990) #> x9      1  new rule1 POINT (436770 5341330)  #--- perform stratified sampling random sampling ---# sample_strat(   sraster = sr,   nSamp = 200,   plot = TRUE,   force = TRUE ) #> Implementing porportional allocation of samples #> Forcing 200 total samples. #> Processing strata : 1 #> Processing strata : 2 #> Processing strata : 3 #> Processing strata : 4 #> Processing strata : 5 #> Processing strata : 6 #> Processing strata : 7 #> Processing strata : 8 #> Processing strata : 9 #> Processing strata : 10  #> Simple feature collection with 200 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337730 xmax: 438510 ymax: 5343190 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>    strata type  rule               geometry #> x       1  new rule1 POINT (433290 5338050) #> x1      1  new rule1 POINT (436770 5341350) #> x2      1  new rule1 POINT (431310 5342670) #> x3      1  new rule1 POINT (437350 5340130) #> x4      1  new rule1 POINT (436770 5341330) #> x5      1  new rule1 POINT (433510 5339190) #> x6      1  new rule1 POINT (433450 5338930) #> x7      1  new rule1 POINT (438490 5340850) #> x8      1  new rule1 POINT (433470 5338930) #> x9      1  new rule1 POINT (432750 5338430)  #--- extract strata values to existing samples ---# e.sr <- extract_strata(sraster = sr, existing = e)  sample_strat(   sraster = sr,   nSamp = 200,   access = ac,   existing = e.sr,   mindist = 200,   buff_inner = 50,   buff_outer = 200 ) #> Implementing porportional allocation of samples #> nSamp of 200 is not perfectly divisible based on strata distribution. nSamp of 199 will be returned. Use \"force = TRUE\" to brute force to 200. #> An access layer has been provided. An internal buffer of 50 m and an external buffer of 200 m have been applied #> Processing strata : 1 #> Buffered area contains 2273 available candidates. Sampling to reach 13 samples starting. #> Processing strata : 2 #> Buffered area contains 6190 available candidates. Sampling to reach 29 samples starting. #> Processing strata : 3 #> Buffered area contains 2213 available candidates. Sampling to reach 14 samples starting. #> Processing strata : 4 #> Buffered area contains 3230 available candidates. Sampling to reach 21 samples starting. #> Processing strata : 5 #> Buffered area contains 4430 available candidates. Sampling to reach 25 samples starting. #> Processing strata : 6 #> Buffered area contains 4338 available candidates. Sampling to reach 24 samples starting. #> Processing strata : 7 #> Buffered area contains 3774 available candidates. Sampling to reach 24 samples starting. #> Processing strata : 8 #> Buffered area contains 4061 available candidates. Sampling to reach 16 samples starting. #> Processing strata : 9 #> Buffered area contains 6063 available candidates. Sampling to reach 23 samples starting. #> Processing strata : 10 #> Buffered area contains 1666 available candidates. Sampling to reach 10 samples starting. #> Simple feature collection with 299 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337730 xmax: 438550 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>    strata     type     rule               geometry #> 36      1 existing existing POINT (431930 5338510) #> 41      1 existing existing POINT (433990 5341870) #> x       1      new    rule1 POINT (431290 5342670) #> x1      1      new    rule1 POINT (438370 5340830) #> x2      1      new    rule1 POINT (438090 5341850) #> x3      1      new    rule2 POINT (437330 5342010) #> x4      1      new    rule2 POINT (436430 5340310) #> x5      1      new    rule2 POINT (432950 5339670) #> x6      1      new    rule2 POINT (432770 5340150) #> x7      1      new    rule2 POINT (438150 5342210)  sample_strat(   sraster = sr,   nSamp = 200,   access = ac,   buff_inner = 50,   buff_outer = 200,   filename = tempfile(fileext = \".shp\") ) #> Implementing porportional allocation of samples #> nSamp of 200 is not perfectly divisible based on strata distribution. nSamp of 199 will be returned. Use \"force = TRUE\" to brute force to 200. #> An access layer has been provided. An internal buffer of 50 m and an external buffer of 200 m have been applied #> Processing strata : 1 #> Buffered area contains 2273 available candidates. Sampling to reach 13 samples starting. #> Processing strata : 2 #> Buffered area contains 6190 available candidates. Sampling to reach 29 samples starting. #> Processing strata : 3 #> Buffered area contains 2213 available candidates. Sampling to reach 14 samples starting. #> Processing strata : 4 #> Buffered area contains 3230 available candidates. Sampling to reach 21 samples starting. #> Processing strata : 5 #> Buffered area contains 4430 available candidates. Sampling to reach 25 samples starting. #> Processing strata : 6 #> Buffered area contains 4338 available candidates. Sampling to reach 24 samples starting. #> Processing strata : 7 #> Buffered area contains 3774 available candidates. Sampling to reach 24 samples starting. #> Processing strata : 8 #> Buffered area contains 4061 available candidates. Sampling to reach 16 samples starting. #> Processing strata : 9 #> Buffered area contains 6063 available candidates. Sampling to reach 23 samples starting. #> Processing strata : 10 #> Buffered area contains 1666 available candidates. Sampling to reach 10 samples starting. #> Writing layer `file55ec294ad2f' to data source  #>   `C:\\Users\\tgood.stu\\AppData\\Local\\Temp\\RtmpMPmhqB\\file55ec294ad2f.shp' using driver `ESRI Shapefile' #> Writing 199 features with 3 fields and geometry type Point. #> Simple feature collection with 199 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431190 ymin: 5337730 xmax: 438510 ymax: 5343190 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>    strata type  rule               geometry #> x       1  new rule1 POINT (438490 5340850) #> x1      1  new rule1 POINT (438090 5341850) #> x2      1  new rule1 POINT (438370 5340830) #> x3      1  new rule1 POINT (431290 5342670) #> x4      1  new rule1 POINT (438390 5340830) #> x5      1  new rule1 POINT (438110 5341850) #> x6      1  new rule1 POINT (431310 5342670) #> x7      1  new rule2 POINT (435310 5339030) #> x8      1  new rule2 POINT (433690 5342530) #> x9      1  new rule2 POINT (436570 5343030)  #--- Load mraster for optimal allocation ---# mr <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(mr)  sample_strat(   sraster = sr,   nSamp = 200,   allocation = \"optim\",   mraster = mr$zq90,   access = ac,   buff_inner = 50,   buff_outer = 200,   filename = tempfile(fileext = \".shp\") ) #> Implementing optimal allocation of samples based on variability of 'zq90' #> nSamp of 200 is not perfectly divisible based on strata distribution. nSamp of 199 will be returned. Use \"force = TRUE\" to brute force to 200. #> An access layer has been provided. An internal buffer of 50 m and an external buffer of 200 m have been applied #> Processing strata : 1 #> Buffered area contains 2273 available candidates. Sampling to reach 17 samples starting. #> Processing strata : 2 #> Buffered area contains 6190 available candidates. Sampling to reach 31 samples starting. #> Processing strata : 3 #> Buffered area contains 2213 available candidates. Sampling to reach 14 samples starting. #> Processing strata : 4 #> Buffered area contains 3230 available candidates. Sampling to reach 17 samples starting. #> Processing strata : 5 #> Buffered area contains 4430 available candidates. Sampling to reach 19 samples starting. #> Processing strata : 6 #> Buffered area contains 4338 available candidates. Sampling to reach 21 samples starting. #> Processing strata : 7 #> Buffered area contains 3774 available candidates. Sampling to reach 23 samples starting. #> Processing strata : 8 #> Buffered area contains 4061 available candidates. Sampling to reach 23 samples starting. #> Processing strata : 9 #> Buffered area contains 6063 available candidates. Sampling to reach 21 samples starting. #> Processing strata : 10 #> Buffered area contains 1666 available candidates. Sampling to reach 13 samples starting. #> Writing layer `file55ec5fa61d51' to data source  #>   `C:\\Users\\tgood.stu\\AppData\\Local\\Temp\\RtmpMPmhqB\\file55ec5fa61d51.shp' using driver `ESRI Shapefile' #> Writing 199 features with 3 fields and geometry type Point. #> Simple feature collection with 199 features and 3 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431290 ymin: 5337790 xmax: 438490 ymax: 5343230 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>    strata type  rule               geometry #> x       1  new rule1 POINT (438390 5340830) #> x1      1  new rule1 POINT (431290 5342670) #> x2      1  new rule1 POINT (438490 5340850) #> x3      1  new rule1 POINT (431310 5342670) #> x4      1  new rule1 POINT (438110 5341850) #> x5      1  new rule1 POINT (438090 5341850) #> x6      1  new rule1 POINT (438370 5340830) #> x7      1  new rule2 POINT (434190 5338550) #> x8      1  new rule2 POINT (434370 5340670) #> x9      1  new rule2 POINT (436650 5341790)"},{"path":"/reference/sample_systematic.html","id":null,"dir":"Reference","previous_headings":"","what":"Systematic sampling — sample_systematic","title":"Systematic sampling — sample_systematic","text":"Systematic sampling within square hexagonal tessellation.","code":""},{"path":"/reference/sample_systematic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Systematic sampling — sample_systematic","text":"","code":"sample_systematic(   raster,   cellsize,   square = TRUE,   location = \"centers\",   access = NULL,   buff_inner = NULL,   buff_outer = NULL,   plot = FALSE,   filename = NULL,   overwrite = FALSE,   details = FALSE,   ... )"},{"path":"/reference/sample_systematic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Systematic sampling — sample_systematic","text":"raster spatRaster. Raster used define extent fishnet grid. cellsize Numeric. Desired cellsize tessellation. square Logical. Tessellation shape. Default regular square grid, FALSE hexagons returned. location Character. Sample location within tessellation. Default (\"centers\") returns samples tessellation centers, \"corners\" - corners returned, \"random\" - samples randomly located within tessellations. access sf. Road access network - must lines. buff_inner Numeric. Inner buffer boundary specifying distance access plots sampled. buff_outer Numeric. Outer buffer boundary specifying distance access plots can sampled. plot Logical. Plots output strata raster samples. filename Character. Path write output samples. overwrite Logical. Choice overwrite existing filename exists. details Logical. FALSE (default) output sf object systematic samples. TRUE returns list sf objects tessellation tessellation grid sampling, samples systematic samples. ... Additional arguments st_make_grid.","code":""},{"path":"/reference/sample_systematic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Systematic sampling — sample_systematic","text":"sf object sampled points tessellation.","code":""},{"path":[]},{"path":"/reference/sample_systematic.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Systematic sampling — sample_systematic","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/sample_systematic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Systematic sampling — sample_systematic","text":"","code":"#--- Load raster and access files ---# r <- system.file(\"extdata\", \"kmeans.tif\", package = \"sgsR\") sr <- terra::rast(r)  a <- system.file(\"extdata\", \"roads.shp\", package = \"sgsR\") ac <- sf::st_read(a) #> Reading layer `roads' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\roads.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 167 features and 2 fields #> Geometry type: MULTILINESTRING #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337700 xmax: 438560 ymax: 5343240 #> Projected CRS: UTM_Zone_17_Northern_Hemisphere  e <- system.file(\"extdata\", \"existing.shp\", package = \"sgsR\") e <- sf::st_read(e) #> Reading layer `existing' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\existing.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 100 features and 1 field #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431110 ymin: 5337750 xmax: 438550 ymax: 5343230 #> CRS:           unknown  #--- perform grid sampling ---# sample_systematic(   raster = sr,   cellsize = 1000,   plot = TRUE )  #> Simple feature collection with 40 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431600 ymin: 5338200 xmax: 437600 ymax: 5343200 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (431600 5338200) #> 2  POINT (432600 5338200) #> 3  POINT (433600 5338200) #> 4  POINT (434600 5338200) #> 5  POINT (435600 5338200) #> 6  POINT (436600 5338200) #> 7  POINT (437600 5338200) #> 8  POINT (432600 5339200) #> 9  POINT (433600 5339200) #> 10 POINT (434600 5339200)  sample_systematic(   raster = sr,   cellsize = 1000,   square = FALSE,   location = \"corners\",   plot = TRUE )  #> Simple feature collection with 312 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337989 xmax: 438100 ymax: 5343185 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (431100 5338855) #> 2  POINT (431100 5338277) #> 3  POINT (431100 5340587) #> 4  POINT (431100 5340009) #> 5  POINT (431100 5342319) #> 6  POINT (431100 5338277) #> 7  POINT (431600 5337989) #> 8  POINT (431100 5338855) #> 9  POINT (431100 5340009) #> 10 POINT (431600 5339721)  sample_systematic(   raster = sr,   cellsize = 1000,   access = ac,   buff_inner = 50,   buff_outer = 200 ) #> An access layer has been provided. An internal buffer of 50 m and an external buffer of 200 m have been applied #> Simple feature collection with 15 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 432600 ymin: 5338200 xmax: 437600 ymax: 5343200 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                  geometry #> 1  POINT (434600 5338200) #> 2  POINT (436600 5338200) #> 3  POINT (432600 5339200) #> 4  POINT (434600 5339200) #> 5  POINT (437600 5339200) #> 6  POINT (435600 5340200) #> 7  POINT (432600 5341200) #> 8  POINT (433600 5341200) #> 9  POINT (434600 5341200) #> 10 POINT (432600 5342200)  sample_systematic(   raster = sr,   cellsize = 1000,   square = FALSE,   location = \"random\" ) #> Simple feature collection with 42 features and 0 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 431445.4 ymin: 5337843 xmax: 438495 ymax: 5343229 #> CRS:           +proj=utm +zone=17 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #> First 10 features: #>                    geometry #> 1  POINT (431445.4 5339583) #> 2  POINT (431842.7 5340005) #> 3  POINT (431473.8 5342375) #> 4  POINT (431733.6 5337928) #> 5  POINT (431742.6 5341008) #> 6  POINT (431989.8 5343229) #> 7  POINT (432328.5 5338429) #> 8  POINT (432408.7 5341789) #> 9  POINT (433333.8 5338130) #> 10 POINT (432979.6 5339617)"},{"path":"/reference/sgsR-package.html","id":null,"dir":"Reference","previous_headings":"","what":"sgsR: Structurally Guided Sampling Approaches using ALS Data — sgsR-package","title":"sgsR: Structurally Guided Sampling Approaches using ALS Data — sgsR-package","text":"package provides functions enable stratification sampling structurally guided sampling using ALS data.","code":""},{"path":[]},{"path":"/reference/sgsR-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"sgsR: Structurally Guided Sampling Approaches using ALS Data — sgsR-package","text":"Maintainer: Tristan RH Goodbody goodbody.t@gmail.com (ORCID) Authors: Nicholas C Coops nicholas.coops@ubc.ca (ORCID)","code":""},{"path":"/reference/strat_breaks.html","id":null,"dir":"Reference","previous_headings":"","what":"Breaks stratification — strat_breaks","title":"Breaks stratification — strat_breaks","text":"Stratify metrics raster using user defined breaks","code":""},{"path":"/reference/strat_breaks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Breaks stratification — strat_breaks","text":"","code":"strat_breaks(   mraster,   mraster2 = NULL,   breaks,   breaks2 = NULL,   plot = FALSE,   details = FALSE,   filename = NULL,   overwrite = FALSE,   ... )"},{"path":"/reference/strat_breaks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Breaks stratification — strat_breaks","text":"mraster Spatraster. Primary covariate raster stratify. mraster2 Spatraster. Secondary covariate raster stratify. breaks Numeric. Vector breakpoints mraster breaks2 Numeric. Vector breakpoints mraster2 (provided) plot Logical. Plots output strata raster visualized strata boundary dividers. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc. ... Additional arguments writing files. See writeRaster.","code":""},{"path":"/reference/strat_breaks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Breaks stratification — strat_breaks","text":"Returns output stratification spatRaster list details = TRUE. list returned: details list output prcomp function raster stratified spatRaster based quantiles plot ggplot histogram object showing distribution break points.","code":""},{"path":[]},{"path":"/reference/strat_breaks.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Breaks stratification — strat_breaks","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/strat_breaks.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Breaks stratification — strat_breaks","text":"","code":"#--- Load raster ---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  #--- create vector breaks ---# br.max <- c(3, 5, 11, 18) br.sd <- c(1, 2, 5)  strat_breaks(   mraster = mr$zq90,   breaks = br.max,   plot = TRUE,   details = TRUE )   #> $details #> $details$breaks #> [1]  3  5 11 18 #>  #> $details$breaks2 #> NULL #>  #>  #> $raster #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      5  #>  #> $plot #> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.  #>   strat_breaks(   mraster = mr$zq90,   mraster2 = mr$zsd,   breaks = br.max,   breaks2 = br.sd,   plot = TRUE )   #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :     17"},{"path":"/reference/strat_kmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"k-means stratification — strat_kmeans","title":"k-means stratification — strat_kmeans","text":"Stratify metrics raster using kmeans algorithm","code":""},{"path":"/reference/strat_kmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"k-means stratification — strat_kmeans","text":"","code":"strat_kmeans(   mraster,   nStrata,   iter = 500,   algorithm = \"Lloyd\",   center = TRUE,   scale = TRUE,   plot = FALSE,   details = FALSE,   filename = NULL,   overwrite = FALSE,   ... )"},{"path":"/reference/strat_kmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"k-means stratification — strat_kmeans","text":"mraster spatRaster. ALS metrics raster. nStrata Character. Number desired strata. iter Numeric. maximum number iterations allowed. algorithm Character. Lloyd (default) MacQueen algorithms. center Logical. Value indicating whether variables shifted zero centered. scale Logical. Value indicating whether variables scaled unit variance plot Logical. Plots output strata raster visualized strata boundary dividers. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc. ... Additional arguments writing files. See writeRaster.","code":""},{"path":"/reference/strat_kmeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"k-means stratification — strat_kmeans","text":"output stratification spatRaster, list details = TRUE.","code":""},{"path":[]},{"path":"/reference/strat_kmeans.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"k-means stratification — strat_kmeans","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/strat_kmeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"k-means stratification — strat_kmeans","text":"","code":"#--- Load raster and access files ---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  #--- perform stratification using k-means ---# kmeans <- strat_kmeans(   mraster = mr,   nStrata = 5 ) #> K-means being performed on 7 layers with 5 centers.  kmeans <- strat_kmeans(   mraster = mr,   nStrata = 5,   iter = 1000,   algorithm = \"MacQueen\",   plot = TRUE,   details = TRUE ) #> K-means being performed on 7 layers with 5 centers.   kmeans <- strat_kmeans(   mraster = mr,   nStrata = 5,   iter = 1000,   plot = TRUE,   filename = tempfile(fileext = \".tif\"),   overwrite = TRUE ) #> K-means being performed on 7 layers with 5 centers."},{"path":"/reference/strat_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Map 2 stratified rasters — strat_map","title":"Map 2 stratified rasters — strat_map","text":"Map stratified rasters combined stratification.","code":""},{"path":"/reference/strat_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map 2 stratified rasters — strat_map","text":"","code":"strat_map(   sraster,   sraster2,   stack = FALSE,   filename = NULL,   overwrite = FALSE,   plot = FALSE,   details = FALSE,   ... )"},{"path":"/reference/strat_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map 2 stratified rasters — strat_map","text":"sraster spatRaster. Primary stratification raster. sraster2 spatRaster. Secondary stratification raster. stack Logical. Default = FALSE. TRUE, output raster 3 layers: strata, strata2, stratamapped. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc. plot Logical. Plots output strata raster visualized strata boundary dividers. details Logical. FALSE (default) output mapped stratified spatRaster object. TRUE return list $outRaster mapped stratified raster, $lookUp lookup table stratification. ... Additional arguments writing files. See writeRaster.","code":""},{"path":"/reference/strat_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map 2 stratified rasters — strat_map","text":"spatRaster object.","code":""},{"path":"/reference/strat_map.html","id":"mapping","dir":"Reference","previous_headings":"","what":"Mapping","title":"Map 2 stratified rasters — strat_map","text":"mapping algorithm take stratification sraster combine overlying strata values sraster2. result stratamapped attribute values inputs combined. .e. strata = 1 strata2 = 1 stratamapped = 11. strata = 2 strata2 = 14 stratamapped = 214.","code":""},{"path":[]},{"path":"/reference/strat_map.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Map 2 stratified rasters — strat_map","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/strat_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Map 2 stratified rasters — strat_map","text":"","code":"#--- load input metrics raster ---# raster <- system.file(\"extdata\", \"kmeans.tif\", package = \"sgsR\") srasterkmeans <- terra::rast(raster)  #--- read polygon coverage ---# poly <- system.file(\"extdata\", \"inventory_polygons.shp\", package = \"sgsR\") fri <- sf::st_read(poly) #> Reading layer `inventory_polygons' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\inventory_polygons.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 632 features and 3 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337700 xmax: 438560 ymax: 5343240 #> Projected CRS: UTM_Zone_17_Northern_Hemisphere  #--- stratify polygon coverage ---# #--- specify polygon attribute to stratify ---#  attribute <- \"NUTRIENTS\"  #--- specify features within attribute & how they should be grouped ---# #--- as a single vector ---#  features <- c(\"poor\", \"rich\", \"medium\")  srasterfri <- strat_poly(   poly = fri,   attribute = attribute,   features = features,   raster = srasterkmeans,   plot = TRUE )   #--- map srasters ---# strat_map(   sraster = srasterfri,   sraster2 = srasterkmeans,   plot = TRUE )  #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :     11  #> max value   :    310   strat_map(   sraster = srasterfri,   sraster2 = srasterkmeans,   stack = TRUE,   details = TRUE,   plot = TRUE ) #> Stacking sraster, sraster2, and their combination (stratamapped).  #> $outRaster #> class       : SpatRaster  #> dimensions  : 277, 373, 3  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> sources     : memory   #>               kmeans.tif   #>               memory   #> names       : strata, strata2, stratamapped  #> min values  :      1,       1,           11  #> max values  :      3,      10,          310  #>  #> $lookUp #>    strata strata2 stratamapped #> 1       3       2           32 #> 2       3       8           38 #> 3       3       7           37 #> 4       3       5           35 #> 5       1       4           14 #> 6       1       1           11 #> 7       1       3           13 #> 8       1       6           16 #> 9       1      10          110 #> 10      3       4           34 #> 11      3       6           36 #> 12      3       1           31 #> 13      1       7           17 #> 14      1       5           15 #> 15      1       9           19 #> 16      1       8           18 #> 17      1       2           12 #> 18      2       8           28 #> 19      2       7           27 #> 20      2      10          210 #> 21      2       4           24 #> 22      2       5           25 #> 23      2       2           22 #> 24      3       3           33 #> 25      3      10          310 #> 26      3       9           39 #> 27      2       6           26 #> 28      2       3           23 #> 29      2       1           21 #> 30      2       9           29 #>"},{"path":"/reference/strat_osb.html","id":null,"dir":"Reference","previous_headings":"","what":"Determine optimum sample boundaries — strat_osb","title":"Determine optimum sample boundaries — strat_osb","text":"Determine optimum sample boundaries algorithm univariate populations using strata.data algorithm.","code":""},{"path":"/reference/strat_osb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Determine optimum sample boundaries — strat_osb","text":"","code":"strat_osb(   mraster,   nStrata,   nSamp,   subset = 1,   plot = FALSE,   details = FALSE,   filename = NULL,   overwrite = FALSE,   ... )"},{"path":"/reference/strat_osb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Determine optimum sample boundaries — strat_osb","text":"mraster spatRaster. ALS metrics raster. nStrata Numeric. Number desired output strata. nSamp Numeric. Number desired samples - used within OSB algorithm help determine break points. subset Numeric. Value 0 1 (default) denoting proportion data use determine optimum sample boundaries. plot Logical. Plots output strata raster visualized strata boundary dividers. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc. ... Additional arguments writing files. See writeRaster.","code":""},{"path":"/reference/strat_osb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Determine optimum sample boundaries — strat_osb","text":"Returns output stratification spatRaster list details = TRUE. list returned: details list output strata.data function OSB optimum stratum boundaries nh optimum sample sizes stratum. osb vector optimum stratum boundaries. breaks matrix associated metric strata break values. raster stratified spatRaster based OSB.","code":""},{"path":"/reference/strat_osb.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Determine optimum sample boundaries — strat_osb","text":"Khan, E. ., Khan, M. G. M., & Ahsan, M. J. (2002). Optimum Stratification: Mathematical Programming Approach. Calcutta Statistical Association Bulletin, 52(1–4), 323–334. https://doi.org/10.1177/0008068320020518 Khan, M. G. M., Nand, N., & Ahmad, N. (2008). Determining optimum strata boundary points using dynamic programming. Survey methodology, 34(2), 205-214. M.G.M. Khan, K.G. Reddy & D.K. Rao (2015) Designing stratified sampling economic business surveys, Journal Applied Statistics, 42:10, 2080-2099, DOI: 10.1080/02664763.2015.1018674","code":""},{"path":[]},{"path":"/reference/strat_osb.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Determine optimum sample boundaries — strat_osb","text":"Tristan R.H. Goodbody","code":""},{"path":[]},{"path":"/reference/strat_pcomp.html","id":null,"dir":"Reference","previous_headings":"","what":"Principal components stratification — strat_pcomp","title":"Principal components stratification — strat_pcomp","text":"Stratify metrics raster using principal components quantile breaks","code":""},{"path":"/reference/strat_pcomp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Principal components stratification — strat_pcomp","text":"","code":"strat_pcomp(   mraster,   nStrata,   nStrata2 = NULL,   center = TRUE,   scale = TRUE,   plot = FALSE,   samp = 1,   details = FALSE,   filename = NULL,   overwrite = FALSE,   ... )"},{"path":"/reference/strat_pcomp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Principal components stratification — strat_pcomp","text":"mraster Spatraster. Covariate raster stratify. nStrata Numeric. Number strata primary principal component. nStrata2 Numeric. Number strata secondary principal component. center Logical. Value indicating whether variables shifted zero centered. scale Logical. Value indicating whether variables scaled unit variance plot Logical. Plots output strata raster visualized strata boundary dividers. samp Numeric. Proportion raster cells plot 0-1. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc. ... Additional arguments passed prcomp.","code":""},{"path":"/reference/strat_pcomp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Principal components stratification — strat_pcomp","text":"Returns output stratification spatRaster list details = TRUE. list returned: details list output prcomp function raster stratified spatRaster based PCA plot ggplot scatter plot object strata colour coded strata boundaries delineated","code":""},{"path":[]},{"path":"/reference/strat_pcomp.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Principal components stratification — strat_pcomp","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/strat_pcomp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Principal components stratification — strat_pcomp","text":"","code":"#--- Load raster and access files ---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  strat_pcomp(   mraster = mr,   nStrata = 5,   plot = TRUE )  #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      5   strat_pcomp(   mraster = mr,   nStrata = 4,   nStrata2 = 4,   plot = TRUE,   details = TRUE )  #> $details #> Standard deviations (1, .., p=9): #> [1] 2.66328897 1.09805898 0.66339469 0.41858538 0.22109594 0.14478794 #> [7] 0.09669328 0.07739106 0.02581106 #>  #> Rotation (n x k) = (9 x 9): #>                PC1         PC2         PC3         PC4         PC5 #> zmax     0.3718561  0.05890652  0.13655303  0.18644188 -0.02967021 #> zmean    0.2892076  0.11179079 -0.94037185  0.11669464 -0.01101177 #> zsd      0.2902484 -0.57132611  0.07358411 -0.03485495 -0.12710815 #> pzabove2 0.2762415  0.57389014  0.11046261 -0.48982874 -0.53278380 #> zq20     0.3222793  0.42913513  0.17765055  0.04688184  0.69772164 #> zq50     0.3621931  0.06711670  0.16260903  0.50497308 -0.03554264 #> zq70     0.3669446 -0.07622676  0.13483825  0.33474905 -0.33679147 #> zq90     0.3576125 -0.24286784  0.04467110 -0.28486752  0.00494469 #> zq95     0.3463317 -0.27351876 -0.03548477 -0.50997312  0.31217248 #>                   PC6          PC7         PC8          PC9 #> zmax     -0.022902433  0.058181544  0.12813760 -0.885232514 #> zmean     0.061423536  0.005559276 -0.04493042  0.001085691 #> zsd       0.373461072 -0.062831197 -0.65029797 -0.015746780 #> pzabove2  0.007219003  0.005909104 -0.23569527  0.052045306 #> zq20      0.371793616 -0.128585416 -0.12943905  0.141020587 #> zq50     -0.525190662  0.398814446 -0.24627692  0.293390931 #> zq70      0.136444231 -0.587797301  0.42249155  0.270652072 #> zq90      0.287643242  0.607152727  0.49439800  0.184814994 #> zq95     -0.583751620 -0.320739852  0.05279230  0.005601089 #>  #> $raster #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :     16  #>  #> $plot  #>   strat_pcomp(   mraster = mr,   nStrata = 3,   nStrata2 = 3,   filename = tempfile(fileext = \".tif\") ) #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      9"},{"path":"/reference/strat_poly.html","id":null,"dir":"Reference","previous_headings":"","what":"Stratify using polygons — strat_poly","title":"Stratify using polygons — strat_poly","text":"Stratify based polygon coverage attributes features.","code":""},{"path":"/reference/strat_poly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stratify using polygons — strat_poly","text":"","code":"strat_poly(   poly,   attribute,   features,   raster,   filename = NULL,   overwrite = FALSE,   plot = FALSE,   details = FALSE,   ... )"},{"path":"/reference/strat_poly.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stratify using polygons — strat_poly","text":"poly sf. Input polygon coverage. e.g. - forest resources inventory coverage. attribute Character. Name attribute within poly stratified features vector/list. Vector list vectors features within attribute guide stratification. raster spatRaster. Raster template enable polygon raster conversion. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc. plot Logical. Plots output spatRaster. details Logical. FALSE (default) output spatRaster object stratified polygon attributes. TRUE return list $outRaster stratified attributes, $lookUp lookup table stratification, poly defined polygon attribute corresponding features / strata ... Additional arguments writing files. See writeRaster.","code":""},{"path":"/reference/strat_poly.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stratify using polygons — strat_poly","text":"spatRaster object.","code":""},{"path":[]},{"path":"/reference/strat_poly.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Stratify using polygons — strat_poly","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/strat_poly.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stratify using polygons — strat_poly","text":"","code":"#--- load input metrics raster ---# raster <- system.file(\"extdata\", \"kmeans.tif\", package = \"sgsR\") sraster <- terra::rast(raster)  #--- read polygon coverage ---# poly <- system.file(\"extdata\", \"inventory_polygons.shp\", package = \"sgsR\") fri <- sf::st_read(poly) #> Reading layer `inventory_polygons' from data source  #>   `C:\\Users\\tgood.stu\\Documents\\R\\win-library\\4.1\\sgsR\\extdata\\inventory_polygons.shp'  #>   using driver `ESRI Shapefile' #> Simple feature collection with 632 features and 3 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XY #> Bounding box:  xmin: 431100 ymin: 5337700 xmax: 438560 ymax: 5343240 #> Projected CRS: UTM_Zone_17_Northern_Hemisphere  #--- stratify polygon coverage ---# #--- specify polygon attribute to stratify ---#  attribute <- \"NUTRIENTS\"  #--- specify features within attribute & how they should be grouped ---# #--- as a single vector ---#  features <- c(\"poor\", \"rich\", \"medium\")  srasterpoly <- strat_poly(   poly = fri,   attribute = attribute,   features = features,   raster = sraster,   plot = TRUE )   #--- or as multiple lists ---#  g1 <- \"poor\" g2 <- c(\"rich\", \"medium\")  features <- list(g1, g2)  srasterpoly <- strat_poly(   poly = fri,   attribute = attribute,   features = features,   raster = sraster,   plot = TRUE,   details = TRUE )"},{"path":"/reference/strat_quantiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantiles stratification — strat_quantiles","title":"Quantiles stratification — strat_quantiles","text":"Stratify metric raster using metric quantiles.","code":""},{"path":"/reference/strat_quantiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantiles stratification — strat_quantiles","text":"","code":"strat_quantiles(   mraster,   mraster2 = NULL,   nStrata,   nStrata2 = NULL,   plot = FALSE,   details = FALSE,   samp = 1,   filename = NULL,   overwrite = FALSE,   ... )"},{"path":"/reference/strat_quantiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantiles stratification — strat_quantiles","text":"mraster spatRaster. ALS metrics raster. mraster2 Spatraster. Secondary covariate raster stratify. nStrata Numeric. Number quantiles stratify primary covariate. nStrata2 Numeric. Number quantiles stratify secondary covariate. plot Logical. Plots output strata raster visualized strata boundary dividers. details Logical. FALSE (default) output  stratification raster. TRUE return list $details additional stratification information  $raster output stratification spatRaster.  @param ... Additional arguments passed kmeans function. samp Numeric. Determines proportion cells plot scatterplot (default = 1).  Lower values reduce visualization time. filename Character. Path write stratified raster disc. overwrite Logical. Specify whether filename overwritten disc. ... Additional arguments writing files. See writeRaster.","code":""},{"path":"/reference/strat_quantiles.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantiles stratification — strat_quantiles","text":"Returns output stratification spatRaster list details = TRUE. list returned: details list output prcomp function raster stratified spatRaster based quantiles plot ggplot histogram / scatter plot object (depends whether metric2 supplied). Histogram shows distribution break points scatter plot shows colour coded strata boundaries.","code":""},{"path":[]},{"path":"/reference/strat_quantiles.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Quantiles stratification — strat_quantiles","text":"Tristan R.H. Goodbody","code":""},{"path":"/reference/strat_quantiles.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantiles stratification — strat_quantiles","text":"","code":"#--- Load raster and existing plots---# r <- system.file(\"extdata\", \"wall_metrics.tif\", package = \"sgsR\") mr <- terra::rast(r)  strat_quantiles(mraster = mr$zq90,                 nStrata = 4,                 plot = TRUE) #> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.   #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :      4   strat_quantiles(mraster = mr$zq90,                  mraster2 = mr$zsd,                 nStrata = 3,                  nStrata2 = 4) #> class       : SpatRaster  #> dimensions  : 277, 373, 1  (nrow, ncol, nlyr) #> resolution  : 20, 20  (x, y) #> extent      : 431100, 438560, 5337700, 5343240  (xmin, xmax, ymin, ymax) #> coord. ref. : UTM Zone 17, Northern Hemisphere  #> source      : memory  #> name        : strata  #> min value   :      1  #> max value   :     12"},{"path":"/reference/tidyeval.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy eval helpers — tidyeval","title":"Tidy eval helpers — tidyeval","text":"sym() creates symbol string syms() creates list symbols character vector. enquo() enquos() delay execution one several function arguments. enquo() returns single quoted expression, like blueprint delayed computation. enquos() returns list quoted expressions. expr() quotes new expression locally. mostly useful build new expressions around arguments captured enquo() enquos(): expr(mean(!!enquo(arg), na.rm = TRUE)). as_name() transforms quoted variable name string. Supplying something else quoted variable name error. unlike as_label() also returns single string supports kind R object input, including quoted function calls vectors. purpose summarise object single label. label often suitable default name. know quoted expression contains (instance expressions captured enquo() variable name, call function, unquoted constant), use as_label(). know quoted simple variable name, like enforce , use as_name(). learn tidy eval use tools, visit https://tidyeval.tidyverse.org Metaprogramming section Advanced R.","code":""}]
